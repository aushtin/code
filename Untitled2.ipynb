{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.cm as cmap\n",
    "import random\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.naive_bayes import  GaussianNB, MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.linear_model import  LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "import time\n",
    "import gc\n",
    "import logging\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "#import lightgbm as lgb\n",
    "\n",
    "#split data\n",
    "def split_dataset(split_size, ts_df, metadata_df):\n",
    "    \n",
    "    print('Splitting dataset of size', metadata_df.shape[0])\n",
    "    labels = pd.DataFrame(metadata_df.iloc[:, 11], columns = ['target'])\n",
    "    metadata_df = metadata_df.drop(['target'], axis = 1)\n",
    "\n",
    "    metadata1, metadata2, labels1, labels2 = train_test_split(metadata_df, labels, test_size = split_size, random_state = 888) \n",
    "\n",
    "    metadata1.loc[:, 'target'] = labels1['target']\n",
    "    metadata2.loc[:, 'target'] = labels2['target']\n",
    "\n",
    "    time_series1 = ts_df.loc[ts_df['object_id'].isin(metadata1.loc[:, 'object_id'])]\n",
    "    time_series2 = ts_df.loc[ts_df['object_id'].isin(metadata2.loc[:, 'object_id'])]\n",
    "\n",
    "    print('The size of the first split is:', metadata1.shape[0])\n",
    "    print('Check number of object ids in time series for first split:', time_series1['object_id'].value_counts().shape[0])\n",
    "    print('The size of the second split is:', metadata2.shape[0])\n",
    "    print('Check number of object ids in time series for second split:', time_series2['object_id'].value_counts().shape[0])\n",
    "\n",
    "    return metadata1, time_series1, metadata2, time_series2\n",
    "\n",
    "def plot_class_dist(metadata):\n",
    "    \n",
    "    #visualize data in pretraining set\n",
    "\n",
    "    #metadata\n",
    "    class_counts = metadata['target'].value_counts()\n",
    "\n",
    "    #we know that the metadata provides a feature that identifies objects as intergalactic (inside our galaxy) and extragalactic (outside our galaxy).  objects. \n",
    "\n",
    "    ig = metadata.loc[metadata['hostgal_specz'] == 0]\n",
    "    ig_class_counts = ig['target'].value_counts()\n",
    "\n",
    "    #display(ig_class_counts)\n",
    "\n",
    "    eg = metadata.loc[metadata['hostgal_specz'] != 0]\n",
    "    eg_class_counts = eg['target'].value_counts()\n",
    "\n",
    "    #display(eg_class_counts)\n",
    "\n",
    "    total_classes = ig_class_counts.size + eg_class_counts.size\n",
    "\n",
    "    plt.bar(range(0, ig_class_counts.size), ig['target'].value_counts())\n",
    "    plt.bar(range(ig_class_counts.size, total_classes), eg['target'].value_counts())\n",
    "    plt.xticks(range(0, total_classes), ig_class_counts.index.tolist() + eg_class_counts.index.tolist())\n",
    "    # plt.xticks(range(ig_class_counts.size, total_classes), eg_class_counts.index)\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('# of Occurrences')\n",
    "    plt.title('Objects Class Occurrence Count')\n",
    "    plt.legend(['Intergalactic', 'Extragalactic'])\n",
    "    \n",
    "    plt.savefig('./figures/classcount.png')\n",
    "\n",
    "def plot_random_light_curves(time_series):\n",
    "    \n",
    "    g = time_series.groupby('object_id')\n",
    "    pt_obj_list = []\n",
    "    for name, group in g:\n",
    "        pt_obj_list.append(name)\n",
    "\n",
    "    plt.rcParams['figure.figsize'] = [15, 8]\n",
    "\n",
    "    obj_id1 = random.choice(pt_obj_list)\n",
    "    obj_id = obj_id1\n",
    "    obj = g.get_group(obj_id)\n",
    "    obj1 = obj.copy()\n",
    "    fig, ax = plt.subplots()\n",
    "    ax = obj.plot.scatter(x = 'mjd', y = 'flux', c = 'passband', cmap = cmap.get_cmap('Set1'), title = 'Object ID ' + str(obj_id), ax = ax )\n",
    "    ax.set_xlabel('mjd')\n",
    "    ax.set_ylabel('flux')\n",
    "    plt.savefig('./figures/lc1.png')\n",
    "    \n",
    "    obj_id2 = random.choice(pt_obj_list)\n",
    "    obj_id = obj_id2\n",
    "    obj = g.get_group(obj_id)\n",
    "    obj2 = obj.copy()\n",
    "    fig, ax = plt.subplots()\n",
    "    ax = obj.plot.scatter(x = 'mjd', y = 'flux', c = 'passband', cmap = cmap.get_cmap('Set1'), title = 'Object ID ' + str(obj_id), ax = ax )\n",
    "    ax.set_xlabel('mjd')\n",
    "    ax.set_ylabel('flux')\n",
    "    plt.savefig('./figures/lc2.png')\n",
    "    \n",
    "    obj_id3 = random.choice(pt_obj_list)\n",
    "    obj_id = obj_id3\n",
    "    obj = g.get_group(obj_id)\n",
    "    obj3 = obj.copy()\n",
    "    fig, ax = plt.subplots()\n",
    "    ax = obj.plot.scatter(x = 'mjd', y = 'flux', c = 'passband', cmap = cmap.get_cmap('Set1'), title = 'Object ID ' + str(obj_id), ax = ax )\n",
    "    ax.set_xlabel('mjd')\n",
    "    ax.set_ylabel('flux')\n",
    "    plt.savefig('./figures/lc3.png')\n",
    "\n",
    "    obj_id4 = random.choice(pt_obj_list)\n",
    "    obj_id = obj_id4\n",
    "    obj = g.get_group(obj_id)\n",
    "    obj4 = obj.copy()\n",
    "    fig, ax = plt.subplots()\n",
    "    ax = obj.plot.scatter(x = 'mjd', y = 'flux', c = 'passband', cmap = cmap.get_cmap('Set1'), title = 'Object ID ' + str(obj_id), ax = ax )\n",
    "    ax.set_xlabel('mjd')\n",
    "    ax.set_ylabel('flux')\n",
    "    plt.savefig('./figures/lc4.png')\n",
    "\n",
    "    obj_id5 = random.choice(pt_obj_list)\n",
    "    obj_id = obj_id5\n",
    "    obj = g.get_group(obj_id)\n",
    "    obj5 = obj.copy()\n",
    "    fig, ax = plt.subplots()\n",
    "    ax = obj.plot.scatter(x = 'mjd', y = 'flux', c = 'passband', cmap = cmap.get_cmap('Set1'), title = 'Object ID ' + str(obj_id), ax = ax )\n",
    "    ax.set_xlabel('mjd')\n",
    "    ax.set_ylabel('flux')\n",
    "    plt.savefig('./figures/lc6.png')\n",
    "\n",
    "    #return object ids and objs in case we want to use later\n",
    "    return [obj_id1, obj_id2, obj_id3, obj_id4, obj_id5], [obj1, obj2, obj3, obj4, obj5]\n",
    "\n",
    "#unused. originally I was normalizing all of the time series, but this did not seem to make a big difference\n",
    "def normalize_ts(ts, metadata):\n",
    "\n",
    "    normalized_ts = ts.copy()\n",
    "    obj_ids = metadata.loc[:, 'object_id']\n",
    "    n_objects = len(obj_ids)\n",
    "    \n",
    "    print('Starting normalization of', n_objects, 'object time series...', end = '')\n",
    "\n",
    "    for i, id in enumerate(obj_ids):\n",
    "        for pb in range(0, 6):\n",
    "            series = normalized_ts.loc[ (normalized_ts.loc[:, 'object_id'] == id), 'flux']\n",
    "            mean = series.mean()\n",
    "            std = series.std()\n",
    "            normalized_ts.loc[ (normalized_ts.loc[:, 'object_id'] == id), 'flux'] = (series - mean) / std\n",
    "        #print(i+1, 'out of', n_objects, 'done...')\n",
    "    \n",
    "    print('done.', n_objects, 'objects have had their time series normalized.')\n",
    "    \n",
    "    return normalized_ts\n",
    "\n",
    "\n",
    "#found a faster way with aggregate()\n",
    "def extract_features2(ts_df, metadata, f_names = ['mean', 'stddev', 'med', 'max', 'min', 'kurt', 'skew', 'diff'], normalized = False):\n",
    "    start = time.time()\n",
    "    print('Extracting time series features for', metadata.shape[0], 'objects...', end = '')\n",
    "\n",
    "    aggregate_dict = {\n",
    "        'flux': ['mean', 'std', 'median', 'max', 'min'],\n",
    "        'flux_err': ['mean', 'std', 'median', 'max', 'min'],\n",
    "        'detected': ['mean']\n",
    "\n",
    "    }\n",
    "\n",
    "    colnames = [f+'_' + agg + str(i)  for i in range(0, 6) for f in aggregate_dict.keys() for agg in aggregate_dict[f]   ]\n",
    "\n",
    "    feats0 = ts_df[ts_df['passband'] == 0].groupby(['object_id']).aggregate(aggregate_dict)\n",
    "    feats0.columns = feats0.columns.droplevel(0)\n",
    "    feats1 = ts_df[ts_df['passband'] == 1].groupby(['object_id']).aggregate(aggregate_dict)\n",
    "    feats1.columns = feats1.columns.droplevel(0)\n",
    "    feats2 = ts_df[ts_df['passband'] == 2].groupby(['object_id']).aggregate(aggregate_dict)\n",
    "    feats2.columns = feats2.columns.droplevel(0)\n",
    "    feats3 = ts_df[ts_df['passband'] == 3].groupby(['object_id']).aggregate(aggregate_dict)\n",
    "    feats3.columns = feats3.columns.droplevel(0)\n",
    "    feats4 = ts_df[ts_df['passband'] == 4].groupby(['object_id']).aggregate(aggregate_dict)\n",
    "    feats4.columns = feats4.columns.droplevel(0)\n",
    "    feats5 = ts_df[ts_df['passband'] == 5].groupby(['object_id']).aggregate(aggregate_dict)\n",
    "    feats5.columns = feats5.columns.droplevel(0)\n",
    "\n",
    "    #merge everything\n",
    "    feats = feats0.merge(feats1, on='object_id')\n",
    "    feats = feats.merge(feats2, on='object_id')\n",
    "    feats = feats.merge(feats3, on='object_id')\n",
    "    feats = feats.merge(feats4, on='object_id')\n",
    "    feats = feats.merge(feats5, on='object_id')\n",
    "    feats.columns = colnames\n",
    "    feats = feats.reset_index()\n",
    "    feats = feats.merge(metadata, on = 'object_id')\n",
    "    feats = feats.fillna(0)\n",
    "    labels = feats.loc[:, 'target']\n",
    "    feats.drop('target', inplace = True, axis = 1)\n",
    "    feats.drop('object_id', inplace = True, axis = 1)\n",
    "    end = time.time()\n",
    "    print('done. Elapsed time was', end-start, 'seconds.' )\n",
    "    \n",
    "    return feats, labels\n",
    "\n",
    "def extract_features3(ts_df, metadata, drop = True):\n",
    "    start = time.time()\n",
    "    #print('Extracting time series features for', metadata.shape[0], 'objects...', end = '')\n",
    "    aggregate_dict = {\n",
    "        'flux': ['mean', 'std', 'median', 'max', 'min'],\n",
    "        'flux_err': ['mean', 'std', 'median', 'max', 'min'],\n",
    "        'detected': ['mean']\n",
    "    }\n",
    "\n",
    "    colnames = [f+'_' + agg + str(i)  for i in range(0, 6) for f in aggregate_dict.keys() for agg in aggregate_dict[f]   ]\n",
    "\n",
    "    feats0 = ts_df[ts_df['passband'] == 0].groupby(['object_id']).aggregate(aggregate_dict)\n",
    "    feats0.columns = feats0.columns.droplevel(0)\n",
    "    feats1 = ts_df[ts_df['passband'] == 1].groupby(['object_id']).aggregate(aggregate_dict)\n",
    "    feats1.columns = feats1.columns.droplevel(0)\n",
    "    feats2 = ts_df[ts_df['passband'] == 2].groupby(['object_id']).aggregate(aggregate_dict)\n",
    "    feats2.columns = feats2.columns.droplevel(0)\n",
    "    feats3 = ts_df[ts_df['passband'] == 3].groupby(['object_id']).aggregate(aggregate_dict)\n",
    "    feats3.columns = feats3.columns.droplevel(0)\n",
    "    feats4 = ts_df[ts_df['passband'] == 4].groupby(['object_id']).aggregate(aggregate_dict)\n",
    "    feats4.columns = feats4.columns.droplevel(0)\n",
    "    feats5 = ts_df[ts_df['passband'] == 5].groupby(['object_id']).aggregate(aggregate_dict)\n",
    "    feats5.columns = feats5.columns.droplevel(0)\n",
    "\n",
    "    #merge everything\n",
    "    feats = feats0.merge(feats1, on='object_id')\n",
    "    feats = feats.merge(feats2, on='object_id')\n",
    "    feats = feats.merge(feats3, on='object_id')\n",
    "    feats = feats.merge(feats4, on='object_id')\n",
    "    feats = feats.merge(feats5, on='object_id')\n",
    "    feats.columns = colnames\n",
    "    feats = feats.reset_index()\n",
    "    feats = feats.merge(metadata, on = 'object_id')\n",
    "    feats = feats.fillna(0)\n",
    "    if drop == True:\n",
    "        feats.drop('object_id', inplace = True, axis = 1)\n",
    "    end = time.time()\n",
    "    #print('done. Elapsed time was', end-start, 'seconds.' )\n",
    "    return feats\n",
    "\n",
    "def dt_cv_curve(parameters, x_train, y_train):\n",
    "    cv_avg_errors = []\n",
    "    best_avg = 0\n",
    "    best_dt_model = None\n",
    "    p_opt = -1\n",
    "    for p in parameters:\n",
    "        model, avg = decision_tree_cv(x_train, y_train, p)\n",
    "        cv_avg_errors.append(1.0-avg)\n",
    "        if avg > best_avg:\n",
    "            best_dt_model = model\n",
    "            best_avg = avg\n",
    "            p_opt = p\n",
    "    \n",
    "    print('The Decision Tree Classifier with the best E_cv was min_sample_split = ', p_opt)\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    plt.sca(ax)\n",
    "    plt.plot(parameters, cv_avg_errors, '-bo')\n",
    "    plt.legend(['avg cv error'])\n",
    "    plt.xlabel('n_estimators')\n",
    "    plt.ylabel('error rate')\n",
    "    plt.ylim(0, .5)\n",
    "    plt.savefig('./figures/dt_cv_curve.png')\n",
    "    return cv_avg_errors, best_dt_model\n",
    "\n",
    "def rf_cv_curve(parameters, x_train, y_train):\n",
    "    cv_avg_errors = []\n",
    "    best_avg = 0\n",
    "    best_RF_model = None\n",
    "    p_opt = -1\n",
    "    for p in parameters:\n",
    "        model, avg = random_forest_cv(x_train, y_train, p)\n",
    "        cv_avg_errors.append(1.0-avg)\n",
    "        if avg > best_avg:\n",
    "            best_RF_model = model\n",
    "            best_avg = avg\n",
    "            p_opt = p\n",
    "    \n",
    "    print('The Random Forest Classifier with the best E_cv was n_estimators = ', p_opt)\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.sca(ax)\n",
    "    plt.plot(parameters, cv_avg_errors, '--gD')\n",
    "    plt.legend(['avg cv error'])\n",
    "    plt.xlabel('n_estimators')\n",
    "    plt.ylabel('error rate')\n",
    "    plt.ylim(0, .5)\n",
    "    plt.savefig('./figures/rf_cv_curve.png')\n",
    "    return cv_avg_errors, best_RF_model\n",
    "\n",
    "def adaboost_cv_curve(parameters, x_train, y_train):\n",
    "    \n",
    "    cv_avg_error_curves = []\n",
    "    \n",
    "    best_avg = 0\n",
    "    best_RF_model = None\n",
    "    p_opt = -1\n",
    "    md_opt = -1\n",
    "    for md in range(1, 6):\n",
    "        \n",
    "        curve = []\n",
    "        \n",
    "        for p in parameters:\n",
    "            model, avg = adaboost_cv(x_train, y_train, p, md)\n",
    "            curve.append(1.0-avg)\n",
    "            if avg > best_avg:\n",
    "                best_AB_model = model\n",
    "                best_avg = avg\n",
    "                md_opt = md\n",
    "                p_opt = p\n",
    "        \n",
    "        cv_avg_error_curves.append(curve)\n",
    "    \n",
    "    print('The OVR Adaboost Classifier with DT base with the best E_cv was n_estimators = ', p_opt, 'max depth =', md_opt)\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.sca(ax)\n",
    "    plt.plot(parameters, cv_avg_error_curves[0], '--gD', \n",
    "             parameters, cv_avg_error_curves[1], '--bo',\n",
    "             parameters, cv_avg_error_curves[2], '--r^',\n",
    "             parameters, cv_avg_error_curves[3], '--k.',\n",
    "             parameters, cv_avg_error_curves[4], '--cx')\n",
    "    \n",
    "    plt.legend(['max_depth = 1','max_depth = 2','max_depth = 3','max_depth = 4','max_depth = 5'])\n",
    "    plt.xlabel('n_estimators')\n",
    "    plt.ylabel('error rate')\n",
    "    plt.ylim(0, .5)\n",
    "    plt.savefig('./figures/ab_cv_curve.png')\n",
    "    return cv_avg_error_curves, best_AB_model\n",
    "\n",
    "def gaussian_naive_bayes_cv(x_train, y_train):\n",
    "    \n",
    "    gnb = GaussianNB()\n",
    "\n",
    "    cv_scores = cross_val_score(gnb, x_train, y_train, cv = StratifiedKFold(5), n_jobs = -1)\n",
    "\n",
    "    print('----------------------------------------------------------------')\n",
    "    print('|****              Gaussian Naive Bayes                     ****|')\n",
    "    print('cv scores: ', *cv_scores.round(5), sep = ' ')\n",
    "    print('cv average:', sum(cv_scores)/5.0)\n",
    "\n",
    "    gnb.fit(x_train, y_train)\n",
    "    \n",
    "    return gnb, sum(cv_scores)/5.0\n",
    "\n",
    "def decision_tree_cv(x_train, y_train, min_samples_split = 2):\n",
    "    \n",
    "    dt = DecisionTreeClassifier(min_samples_split = min_samples_split)\n",
    "\n",
    "    cv_scores = cross_val_score(dt, x_train, y_train, cv = StratifiedKFold(5), n_jobs = -1)\n",
    "\n",
    "    print('----------------------------------------------------------------')\n",
    "    print('|****                Decision    Tree                     ****|')\n",
    "    print('cv scores: ', *cv_scores.round(5), sep = ' ')\n",
    "    print('cv average:', sum(cv_scores)/5.0)\n",
    "\n",
    "    dt.fit(x_train, y_train)\n",
    "    \n",
    "    return dt, sum(cv_scores)/5.0\n",
    "\n",
    "def random_forest_cv(x_train, y_train, nest=300, min_split=2):\n",
    "    \n",
    "    rf = RandomForestClassifier(n_estimators = nest, min_samples_split = min_split)\n",
    "\n",
    "    cv_scores = cross_val_score(rf, x_train, y_train, cv = StratifiedKFold(5), n_jobs = -1)\n",
    "\n",
    "    print('----------------------------------------------------------------')\n",
    "    print('|****        Random Forest, n_estimators = ', nest, '               ****|')\n",
    "    print('cv scores: ', *cv_scores.round(5), sep = ' ')\n",
    "    print('cv average:', sum(cv_scores)/5.0)\n",
    "\n",
    "    rf.fit(x_train, y_train)\n",
    "    \n",
    "    return rf, sum(cv_scores)/5.0\n",
    "\n",
    "#unused. was testing out an idea to split ig and eg objects\n",
    "def split_random_forest_cv(x_train, y_train, ig_model, eg_model):\n",
    "    \n",
    "\n",
    "    skf = StratifiedKFold(n_splits = 5)\n",
    "    \n",
    "    total_scores = []\n",
    "    cv_scores = []\n",
    "    \n",
    "    for train_idx, test_idx in skf.split(x_train, y_train):\n",
    "        train_data, train_labels = x_train.iloc[train_idx], y_train.iloc[train_idx]\n",
    "        test_data, test_labels = x_train.iloc[test_idx], y_train.iloc[test_idx]\n",
    "        \n",
    "        ig_x_train, ig_y_train, eg_x_train, eg_y_train = separate_inter_extragalactic(train_data, train_labels)\n",
    "        ig_x_test, ig_y_test, eg_x_test, eg_y_test= separate_inter_extragalactic(test_data, test_labels)\n",
    "        \n",
    "        #get ig score\n",
    "        ig_model.fit(ig_x_train, ig_y_train)\n",
    "        eg_model.fit(eg_x_train, eg_y_train)\n",
    "        \n",
    "        total_score = accuracy_score(ig_model.predict(ig_x_test), ig_y_test, normalize = False) + accuracy_score(eg_model.predict(eg_x_test), eg_y_test, normalize = False)\n",
    "        accuracy = total_score / test_labels.shape[0]\n",
    "        total_scores.append(total_score)\n",
    "        cv_scores.append(np.round(accuracy, 5)) \n",
    "\n",
    "    print('----------------------------------------------------------------')\n",
    "    print('|****            Random    Forest                     ****|')\n",
    "    print('cv scores: ', *cv_scores, sep = ' ')\n",
    "    print('raw scores:', *total_scores, sep = ' ')\n",
    "    print('cv average:', sum(cv_scores)/5.0)\n",
    "    \n",
    "    ig_x_train, ig_y_train, eg_x_train, eg_y_train = separate_inter_extragalactic(x_train, y_train)\n",
    "    \n",
    "    ig_model.fit(ig_x_train, ig_y_train)\n",
    "    eg_model.fit(eg_x_train, eg_y_train)\n",
    "    \n",
    "    \n",
    "    return ig_model, eg_model, sum(cv_scores)/5.0\n",
    "\n",
    "\n",
    "def adaboost_cv(x_train, y_train, n_estimators = 100, max_depth = 2):\n",
    "    \n",
    "    ab = OneVsRestClassifier(AdaBoostClassifier(DecisionTreeClassifier(max_depth = max_depth), n_estimators = n_estimators))\n",
    "\n",
    "    cv_scores = cross_val_score(ab, x_train, y_train, cv = StratifiedKFold(5), n_jobs = -1)\n",
    "\n",
    "    print('----------------------------------------------------------------')\n",
    "    print('|****    Adaboost with DT base, n_estimators = ', n_estimators, 'max_depth =', max_depth, '    ****')\n",
    "    print('cv scores: ', *cv_scores.round(5), sep = ' ')\n",
    "    print('cv average:', sum(cv_scores)/5.0)\n",
    "\n",
    "    ab.fit(x_train, y_train)\n",
    "    \n",
    "    return ab, sum(cv_scores)/5.0\n",
    "    \n",
    "\n",
    "def separate_inter_extragalactic(features, labels):\n",
    "    \n",
    "    df = features.copy()\n",
    "    df.loc[:, 'target'] = labels\n",
    "    \n",
    "    ig_df = df.loc[df['hostgal_specz'] == 0].copy()\n",
    "\n",
    "    eg_df = df.loc[df['hostgal_specz'] != 0].copy()\n",
    "    \n",
    "    eg_labels = eg_df['target']\n",
    "    ig_labels = ig_df['target']\n",
    "    eg_df.drop('target', inplace = True, axis = 1)\n",
    "    ig_df.drop('target', inplace = True, axis = 1)\n",
    "    \n",
    "    return ig_df, ig_labels, eg_df, eg_labels\n",
    "\n",
    "def separate_inter_extragalactic2(features):\n",
    "    \n",
    "    df = features.copy()\n",
    "    \n",
    "    ig_df = df.loc[df['hostgal_specz'] == 0].copy()\n",
    "\n",
    "    eg_df = df.loc[df['hostgal_specz'] != 0].copy()\n",
    "    \n",
    "    return ig_df, eg_df\n",
    "\n",
    "def train_model(training_features, training_labels):\n",
    "    \n",
    "    \n",
    "    rf = RandomForestClassifier(n_estimators = 500)\n",
    "    cv_scores = cross_val_score(rf, training_features, training_labels, cv = StratifiedKFold(5))\n",
    "    cv_avg = sum(cv_scores)/5.0\n",
    "    \n",
    "    print('----------------------------------------------------------------')\n",
    "    print('|****               Random Forest Classifier               ****|')\n",
    "    print('cv scores: ', *cv_scores.round(5), sep = ' ')\n",
    "\n",
    "    rf.fit(training_features, training_labels)\n",
    "    rf_score = rf.score(test_features, test_labels)\n",
    "    print('Dtest score:', round(rf_score, 5))\n",
    "    print('----------------------------------------------------------------\\n\\n')    \n",
    "    \n",
    "    return rf\n",
    "\n",
    "def the_unique(x):\n",
    "    return [x[i] for i in range(len(x)) if x[i] != x[i-1]]\n",
    "\n",
    "\n",
    "def predict(ts, metadata, model):\n",
    "    \n",
    "    #extract features\n",
    "    metadata = metadata.reset_index(drop = True)\n",
    "    features = extract_features3(ts, metadata)\n",
    "    \n",
    "    #predict\n",
    "    probs = model.predict_proba(features)\n",
    "    colnames = ['class_' + str(c) for c in model.classes_]\n",
    "    \n",
    "    probs_df = pd.DataFrame(probs, columns = colnames)\n",
    "    probs_df = probs_df.reset_index(drop = True)\n",
    "    \n",
    "    probs_df['class_99'] = (1.0 - probs).prod(axis = 1) #does not show up in training set. so just calculate probability of not being any of the other classes\n",
    "    \n",
    "\n",
    "    #add object id back in (need it for the .csv format of the kaggle submission)\n",
    "    probs_df.insert(0, 'object_id', metadata['object_id'])\n",
    "    \n",
    "    #make sure everything went okay...\n",
    "    in_count = metadata.shape[0]\n",
    "    out_count = probs_df.shape[0]\n",
    "    first_in = metadata.iloc[0, 0]\n",
    "    first_out = probs_df.iloc[0,0]\n",
    "    if (first_in != first_out):\n",
    "        print('something happened when reading in the ts starting with', ts.iloc[0, 0], '. first in =', first_in, 'first out =', first_out)\n",
    "    if (in_count !=out_count):\n",
    "        print('something happened when reading in the ts starting with', ts.iloc[0, 0])\n",
    "        \n",
    "    gc.collect()\n",
    "    \n",
    "    return probs_df\n",
    "\n",
    "#using the split models for intergalactic and extra galactic\n",
    "def predict2(ts, metadata, model1, model2):\n",
    "    \n",
    "    #extract features\n",
    "    metadata = metadata.reset_index(drop = True)\n",
    "    features = extract_features3(ts, metadata, drop = False)\n",
    "    \n",
    "    #split\n",
    "    ig_feats, eg_feats = separate_inter_extragalactic2(features)\n",
    "    ig_objs = ig_feats['object_id'].copy()\n",
    "    eg_objs = eg_feats['object_id'].copy()\n",
    "    \n",
    "    all_obj_ids = ig_objs.append(eg_objs, ignore_index = True)\n",
    "    ig_feats.drop('object_id', inplace = True, axis = 1)\n",
    "    eg_feats.drop('object_id', inplace = True, axis = 1)\n",
    "    \n",
    "    #predict\n",
    "    if ig_feats.empty ==False:\n",
    "        probs1 = model1.predict_proba(ig_feats)\n",
    "        ig_probs = np.append(probs1, np.zeros((probs1.shape[0], 9)), axis = 1)\n",
    "    \n",
    "    if eg_feats.empty == False:\n",
    "        probs2 = model2.predict_proba(eg_feats)\n",
    "        eg_probs = np.append(np.zeros((probs2.shape[0], 5)), probs2, axis = 1)\n",
    "    \n",
    "#     if eg_probs.shape[1] != ig_probs.shape[1]:\n",
    "#         print('Error. mismatched shapes between eg_probs and ig_probs')\n",
    "\n",
    "    if (eg_feats.empty == False) and (ig_feats.empty ==False) :\n",
    "        probs = np.append(ig_probs, eg_probs, axis = 0)\n",
    "    elif (eg_feats.empty == False) and (ig_feats.empty ==True):\n",
    "        probs = eg_probs\n",
    "        print('last one is extragalactic')\n",
    "        display(ig_feats)\n",
    "        display(eg_feats)\n",
    "    elif (eg_feats.empty == True) and (ig_feats.empty ==False):\n",
    "        probs = ig_probs\n",
    "        print('last one is intergalactic')\n",
    "        display(ig_feats)\n",
    "        display(eg_feats)\n",
    "    else:\n",
    "        display(ig_feats)\n",
    "        display(eg_feats)\n",
    "    colnames = [(\"class_\" + str(c)) for sublist in [model1.classes_, model2.classes_] for c in sublist]\n",
    "    \n",
    "    probs_df = pd.DataFrame(probs, columns = colnames)\n",
    "    probs_df = probs_df.reset_index(drop = True)\n",
    "    \n",
    "    probs_df['class_99'] = (1.0 - probs).prod(axis = 1) #does not show up in training set. so just calculate probability of not being any of the other classes\n",
    "    \n",
    "    #add object id back in (need it for the .csv format of the kaggle submission)\n",
    "    probs_df.insert(0, 'object_id', all_obj_ids)\n",
    "    \n",
    "    #make sure everything went okay...\n",
    "    in_count = metadata.shape[0]\n",
    "    out_count = probs_df.shape[0]\n",
    "    first_in = metadata.iloc[0, 0]\n",
    "    first_out = probs_df.iloc[0,0]\n",
    "    if (in_count !=out_count):\n",
    "        print('something happened when reading in the ts starting with', ts.iloc[0, 0])\n",
    "        \n",
    "    gc.collect()\n",
    "    \n",
    "    return probs_df\n",
    "\n",
    "\n",
    "#generates a .csv for the kaggle competition. the test set is extremely large, \n",
    "#so we have to read it in chunks and make predictions as we go along.\n",
    "def generate_kaggle_submission(model, model2 = None, split = False):\n",
    "\n",
    "    start = time.time()\n",
    "    leftover_ts = None   #each chunk will likely cut off in the middle of a time series. we therefore put the final time series\n",
    "                        #in each chunk (the to the side and add it to the beginning of the next chunk\n",
    "                       \n",
    "    chunksize = 4000000\n",
    "    \n",
    "    test_set_md = pd.read_csv('../data/test_set_metadata.csv')\n",
    "    test_set_md.sort_values(by = 'object_id' , inplace = True, axis = 0)\n",
    "    test_set_md = test_set_md.reset_index(drop = True)\n",
    "    \n",
    "    count = 0 #keep track of rows\n",
    "\n",
    "    for i, df in enumerate(pd.read_csv('../data/test_set.csv', chunksize=chunksize, iterator=True)):\n",
    "        # Check object_ids\n",
    "        # I believe np.unique keeps the order of group_ids as they appear in the file\n",
    "        # My belief is wrong (I should have read the doc !)\n",
    "        # A big thank you to https://www.kaggle.com/filby89\n",
    "        # Use .tolist() is almost 3 times faster than the_unique(df['object_id'].values)\n",
    "        object_ids = the_unique(df['object_id'].tolist())\n",
    "        new_leftover_ts = df.loc[df['object_id'] == object_ids[-1]].copy()\n",
    "\n",
    "\n",
    "        if leftover_ts is None:\n",
    "            df = df.loc[df['object_id'].isin(object_ids[:-1])].copy()\n",
    "        else:\n",
    "            new_df = df.loc[df['object_id'].isin(object_ids[:-1])].copy()\n",
    "            df = pd.concat([leftover_ts, new_df], axis=0)\n",
    "            \n",
    "            #make sure our leftover df gets added correctly\n",
    "            if (df.shape[0] != (leftover_ts.shape[0] + new_df.shape[0])):\n",
    "                print('size of df is', df.shape[0], '. should be', leftover_ts.shape[0] + new_df.shape[0])\n",
    "        \n",
    "        leftover_ts = new_leftover_ts.copy()\n",
    "        \n",
    "        if split==True:\n",
    "            probs_df = predict2(ts= df, metadata = test_set_md.loc[test_set_md['object_id'].isin(object_ids[:-1])], model1 = model, model2 = model2)\n",
    "        else:\n",
    "            probs_df = predict(ts= df, metadata = test_set_md.loc[test_set_md['object_id'].isin(object_ids[:-1])], model = model)\n",
    "\n",
    "        count = count + probs_df.shape[0]\n",
    "        \n",
    "        if i == 0:\n",
    "            probs_df.to_csv('../submissions/submission.csv', header=True, index=False, float_format='%.6f')\n",
    "        else:\n",
    "            probs_df.to_csv('../submissions/submission.csv', header=False, mode='a', index=False, float_format='%.6f')\n",
    "        print('Written', count, 'rows out of 3492890')\n",
    "\n",
    "        gc.collect()\n",
    "\n",
    "    if split==True:\n",
    "        probs_df = predict2(ts= leftover_ts, metadata = test_set_md.loc[test_set_md['object_id'].isin([object_ids[-1]])], model1 = model, model2 = model2)\n",
    "    else:\n",
    "        probs_df = predict(ts= leftover_ts, metadata = test_set_md.loc[test_set_md['object_id'].isin([object_ids[-1]])], model = model)\n",
    "\n",
    "   \n",
    "    count = count + probs_df.shape[0]\n",
    "    probs_df.to_csv('../submissions/submission.csv', header=False, mode='a', index=False, float_format='%.6f')\n",
    "    print('Done. The final row count is', count)\n",
    "    print('That took', np.round( (time.time() - start) / 60 , 2 ), 'minutes')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ig_ab' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-df382f28731b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mig_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meg_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_cv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_random_forest_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mig_ab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meg_rf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ig_ab' is not defined"
     ]
    }
   ],
   "source": [
    "ig_model, eg_model, avg_cv = split_random_forest_cv(training_features, training_labels, ig_ab, eg_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting dataset of size 7848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aushtin/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:362: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/home/aushtin/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the first split is: 6278\n",
      "Check number of object ids in time series for first split: 6278\n",
      "The size of the second split is: 1570\n",
      "Check number of object ids in time series for second split: 1570\n",
      "Splitting dataset of size 6278\n",
      "The size of the first split is: 5650\n",
      "Check number of object ids in time series for first split: 5650\n",
      "The size of the second split is: 628\n",
      "Check number of object ids in time series for second split: 628\n",
      "Extracting time series features for 5650 objects...done. Elapsed time was 0.42107486724853516 seconds.\n",
      "Extracting time series features for 1570 objects...done. Elapsed time was 0.29686522483825684 seconds.\n",
      "----------------------------------------------------------------\n",
      "|****              Gaussian Naive Bayes                     ****|\n",
      "cv scores:  0.20317 0.27675 0.23915 0.24379 0.43378\n",
      "cv average: 0.2793268526372935\n",
      "----------------------------------------------------------------\n",
      "|****                Decision    Tree                     ****|\n",
      "cv scores:  0.62621 0.67728 0.66342 0.64273 0.62222\n",
      "cv average: 0.6463715485049822\n",
      "----------------------------------------------------------------\n",
      "|****        Random Forest, n_estimators =  300                ****|\n",
      "cv scores:  0.72383 0.77984 0.77325 0.74291 0.72622\n",
      "cv average: 0.7492112378692539\n"
     ]
    }
   ],
   "source": [
    "D_ts = pd.read_csv('../data/training_set.csv')\n",
    "D_metadata = pd.read_csv('../data/training_set_metadata.csv')\n",
    "\n",
    "Dpp_metadata, Dpp_ts, test_set_metadata, test_set = split_dataset(0.2, D_ts, D_metadata)\n",
    "training_set_metadata, training_set, pretraining_set_metadata, pretraining_set = split_dataset(0.1, Dpp_ts, Dpp_metadata)\n",
    "\n",
    "plot_class_dist(pretraining_set_metadata)\n",
    "object_ids, objects = plot_random_light_curves(pretraining_set)\n",
    "\n",
    "#normalized_training_set = normalize_ts(training_set, training_set_metadata)\n",
    "\n",
    "# features = extract_features(training_set, training_set_metadata, normalized = False)\n",
    "# training_labels = training_set_metadata['target'].reset_index(drop = True)\n",
    "# training_features= addFeatsToMetadata(training_set_metadata, features)\n",
    "\n",
    "# features = extract_features(normalized_training_set, training_set_metadata, normalized = False)\n",
    "# training_labels = training_set_metadata['target']\n",
    "# nm_training_features= addFeatsToMetadata(training_set_metadata, features)\n",
    "\n",
    "training_features, training_labels = extract_features2(training_set, training_set_metadata)\n",
    "test_features, test_labels = extract_features2(test_set, test_set_metadata)\n",
    "# normalized_training_set = normalize_ts(training_set, training_set_metadata)\n",
    "# normalized_test_set = normalize_ts(test_set, test_set_metadata)\n",
    "\n",
    "# norm_training_features, training_labels = extract_features2(normalized_training_set, training_set_metadata)\n",
    "# norm_test_features, test_labels = extract_features2(normalized_test_set, test_set_metadata)\n",
    "\n",
    "gnb, gnb_avg_cv = gaussian_naive_bayes_cv(norm_training_features, training_labels)\n",
    "dt, dt_avg_cv = decision_tree_cv(training_features, training_labels)\n",
    "rf, rf_avg_cv = random_forest_cv(training_features, training_labels)\n",
    "ab, ab_avg_cv = adaboost_cv(training_features, training_labels)\n",
    "\n",
    "# dt_params = range(2, 20)\n",
    "# dt_avg_errs, best_dt = dt_cv_curve(dt_params, training_features, training_labels)\n",
    "\n",
    "# rf_params = range(40, 1000, 20)\n",
    "# rf_avg_errs, best_rf = rf_cv_curve(rf_params, training_features, training_labels)\n",
    "\n",
    "ab_params = range(100, 1000, 100)\n",
    "ab_avg_errs, best_ab = adaboost_cv_curve(ab_params,training_features, training_labels)\n",
    "\n",
    "# ig_training_features, ig_training_labels, eg_training_features, eg_training_labels = separate_inter_extragalactic(training_features, training_labels)\n",
    "# ig_test_features, ig_test_labels, eg_test_features, eg_test_labels = separate_inter_extragalactic(test_features, test_labels)\n",
    "\n",
    "# ig_gnb, ig_gnb_avg_cv = gaussian_naive_bayes_cv(ig_training_features, ig_training_labels)\n",
    "# ig_dt, ig_dt_avg_cv = decision_tree_cv(ig_training_features, ig_training_labels)\n",
    "# ig_rf, ig_rf_avg_cv = random_forest_cv(ig_training_features, ig_training_labels)\n",
    "# ig_ab, ig_ab_avg_cv = adaboost_cv(ig_training_features, ig_training_labels)\n",
    "\n",
    "\n",
    "# eg_gnb, eg_gnb_avg_cv = gaussian_naive_bayes_cv(eg_training_features, eg_training_labels)\n",
    "# eg_dt, eg_dt_avg_cv = decision_tree_cv(eg_training_features, eg_training_labels)\n",
    "# eg_rf, eg_rf_avg_cv = random_forest_cv(eg_training_features, eg_training_labels)\n",
    "# eg_ab, eg_ab_avg_cv = adaboost_cv(eg_training_features, eg_training_labels)\n",
    "# eg_svm, eg_svm_avg_cv = SVC_cv(eg_training_features, eg_training_labels)\n",
    "\n",
    "#ig_model, eg_model, avg_cv = split_random_forest_cv(training_features, training_labels, nest = 300, min_split = 4)\n",
    "#rf, rf_avg_cv = random_forest_cv(training_features, training_labels, nest = 300, min_split = 4)\n",
    "# ig_rf, ig_rf_avg_cv = random_forest_cv(ig_training_features, ig_training_labels, nest = 300, min_split = 4)\n",
    "\n",
    "\n",
    "# params = range(2, 20, 1)\n",
    "# cv_curve2(params, training_features, training_labels, test_features, test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "|****              Gaussian Naive Bayes                     ****|\n",
      "cv scores:  0.44415 0.44385 0.43756 0.41667 0.40711\n",
      "cv average: 0.4298678814734573\n",
      "The E_test of the GNB Classifier on the test set is 0.5898089171974522\n",
      "The E_train of the GNB Classifier on the train set is 0.5663716814159292\n",
      "----------------------------------------------------------------\n",
      "|****              Gaussian Naive Bayes                     ****|\n",
      "cv scores:  0.26385 0.31123 0.30381 0.27305 0.28356\n",
      "cv average: 0.287099024964374\n",
      "The E_test of the GNB Classifier on the test set with TS features is 0.721656050955414\n",
      "The E_train of the GNB Classifier on the train set with TS features is 0.7099115044247788\n",
      "The E_train of the best Decision Tree Classifier on the train set is 0.0\n",
      "The E_test of the best Decision Tree Classifier on the test set is 0.3203821656050956\n",
      "The E_test of the best Random Forest Classifier on the test set is 0.0\n",
      "The E_test of the best Random Forest Classifier on the test set is 0.23439490445859867\n"
     ]
    }
   ],
   "source": [
    "# model = train_model(training_features, training_labels)\n",
    "gnb, gnb_avg_cv = gaussian_naive_bayes_cv((training_set_metadata.iloc[:, 1:10]).fillna(0), training_set_metadata['target'])\n",
    "print('The E_test of the GNB Classifier on the test set is', 1.0-gnb.score(test_set_metadata.iloc[:, 1:10].fillna(0), test_set_metadata['target']))\n",
    "print('The E_train of the GNB Classifier on the train set is', 1.0-gnb.score((training_set_metadata.iloc[:, 1:10]).fillna(0), training_set_metadata['target']))\n",
    "\n",
    "gnb, gnb_avg_cv = gaussian_naive_bayes_cv(training_features, training_labels)\n",
    "print('The E_test of the GNB Classifier on the test set with TS features is', 1.0-gnb.score(test_features, test_labels))\n",
    "print('The E_train of the GNB Classifier on the train set with TS features is', 1.0-gnb.score(training_features, training_labels))\n",
    "\n",
    "best_dt_test_score = best_dt.score(test_features, test_labels)\n",
    "best_dt_train_score = best_dt.score(training_features, training_labels)\n",
    "print('The E_train of the best Decision Tree Classifier on the train set is', 1.0-best_dt_train_score)\n",
    "print('The E_test of the best Decision Tree Classifier on the test set is', 1.0-best_dt_test_score)\n",
    "\n",
    "best_rf_train_score = best_rf.score(training_features, training_labels)\n",
    "best_rf_test_score = best_rf.score(test_features, test_labels)\n",
    "print('The E_test of the best Random Forest Classifier on the test set is', 1.0-best_rf_train_score)\n",
    "print('The E_test of the best Random Forest Classifier on the test set is', 1.0-best_rf_test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plt.sca(ax)\n",
    "plt.plot(rf_params, rf_avg_errs, '-bo')\n",
    "plt.legend(['avg cv error'])\n",
    "plt.xlabel('min_sample_split')\n",
    "plt.ylabel('error rate')\n",
    "plt.title('Random Forest: Avg CV Err vs n_estimators')\n",
    "plt.ylim(0, .5)\n",
    "plt.savefig('./figures/rfcvcurve.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flux_mean0</th>\n",
       "      <th>flux_std0</th>\n",
       "      <th>flux_median0</th>\n",
       "      <th>flux_max0</th>\n",
       "      <th>flux_min0</th>\n",
       "      <th>flux_err_mean0</th>\n",
       "      <th>flux_err_std0</th>\n",
       "      <th>flux_err_median0</th>\n",
       "      <th>flux_err_max0</th>\n",
       "      <th>flux_err_min0</th>\n",
       "      <th>...</th>\n",
       "      <th>ra</th>\n",
       "      <th>decl</th>\n",
       "      <th>gal_l</th>\n",
       "      <th>gal_b</th>\n",
       "      <th>ddf</th>\n",
       "      <th>hostgal_specz</th>\n",
       "      <th>hostgal_photoz</th>\n",
       "      <th>hostgal_photoz_err</th>\n",
       "      <th>distmod</th>\n",
       "      <th>mwebv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.254554</td>\n",
       "      <td>83.944735</td>\n",
       "      <td>-10.015225</td>\n",
       "      <td>125.182808</td>\n",
       "      <td>-116.913223</td>\n",
       "      <td>3.823448</td>\n",
       "      <td>0.493621</td>\n",
       "      <td>3.866380</td>\n",
       "      <td>4.737393</td>\n",
       "      <td>2.844200</td>\n",
       "      <td>...</td>\n",
       "      <td>349.046051</td>\n",
       "      <td>-61.943836</td>\n",
       "      <td>320.796530</td>\n",
       "      <td>-51.753706</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.797523</td>\n",
       "      <td>4.374445</td>\n",
       "      <td>1.056714</td>\n",
       "      <td>18.014029</td>\n",
       "      <td>-3.874349</td>\n",
       "      <td>1.954723</td>\n",
       "      <td>0.520573</td>\n",
       "      <td>1.877306</td>\n",
       "      <td>3.093587</td>\n",
       "      <td>0.957792</td>\n",
       "      <td>...</td>\n",
       "      <td>0.189873</td>\n",
       "      <td>-45.586655</td>\n",
       "      <td>328.254458</td>\n",
       "      <td>-68.969298</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3037</td>\n",
       "      <td>0.2813</td>\n",
       "      <td>1.1523</td>\n",
       "      <td>40.7951</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.660948</td>\n",
       "      <td>2.360084</td>\n",
       "      <td>0.581027</td>\n",
       "      <td>5.330927</td>\n",
       "      <td>-6.804703</td>\n",
       "      <td>2.251139</td>\n",
       "      <td>0.566168</td>\n",
       "      <td>2.153805</td>\n",
       "      <td>3.658313</td>\n",
       "      <td>1.208098</td>\n",
       "      <td>...</td>\n",
       "      <td>352.711273</td>\n",
       "      <td>-63.823658</td>\n",
       "      <td>316.922299</td>\n",
       "      <td>-51.059403</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1934</td>\n",
       "      <td>0.2415</td>\n",
       "      <td>0.0176</td>\n",
       "      <td>40.4166</td>\n",
       "      <td>0.024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.888847</td>\n",
       "      <td>52.335031</td>\n",
       "      <td>0.361674</td>\n",
       "      <td>276.159576</td>\n",
       "      <td>-7.049055</td>\n",
       "      <td>2.292132</td>\n",
       "      <td>0.521717</td>\n",
       "      <td>2.243897</td>\n",
       "      <td>3.585604</td>\n",
       "      <td>1.333190</td>\n",
       "      <td>...</td>\n",
       "      <td>347.846710</td>\n",
       "      <td>-64.760857</td>\n",
       "      <td>318.929827</td>\n",
       "      <td>-49.143596</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1352</td>\n",
       "      <td>0.1820</td>\n",
       "      <td>0.0304</td>\n",
       "      <td>39.7279</td>\n",
       "      <td>0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.107645</td>\n",
       "      <td>2.100048</td>\n",
       "      <td>-0.258138</td>\n",
       "      <td>5.241472</td>\n",
       "      <td>-3.751457</td>\n",
       "      <td>2.223667</td>\n",
       "      <td>0.562132</td>\n",
       "      <td>2.128103</td>\n",
       "      <td>3.632440</td>\n",
       "      <td>1.193795</td>\n",
       "      <td>...</td>\n",
       "      <td>348.595886</td>\n",
       "      <td>-63.072620</td>\n",
       "      <td>320.023289</td>\n",
       "      <td>-50.713060</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6857</td>\n",
       "      <td>0.7014</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>43.1524</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.225061</td>\n",
       "      <td>6.770588</td>\n",
       "      <td>0.631169</td>\n",
       "      <td>22.368912</td>\n",
       "      <td>-3.560047</td>\n",
       "      <td>2.244314</td>\n",
       "      <td>0.620582</td>\n",
       "      <td>2.045203</td>\n",
       "      <td>3.402587</td>\n",
       "      <td>1.514232</td>\n",
       "      <td>...</td>\n",
       "      <td>149.414062</td>\n",
       "      <td>3.433834</td>\n",
       "      <td>234.919132</td>\n",
       "      <td>42.245550</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3088</td>\n",
       "      <td>0.3229</td>\n",
       "      <td>0.3360</td>\n",
       "      <td>41.1401</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.658652</td>\n",
       "      <td>2.860190</td>\n",
       "      <td>0.246219</td>\n",
       "      <td>7.164557</td>\n",
       "      <td>-7.061294</td>\n",
       "      <td>2.221272</td>\n",
       "      <td>0.582866</td>\n",
       "      <td>1.997216</td>\n",
       "      <td>3.323257</td>\n",
       "      <td>1.565513</td>\n",
       "      <td>...</td>\n",
       "      <td>149.414062</td>\n",
       "      <td>1.940072</td>\n",
       "      <td>236.565366</td>\n",
       "      <td>41.393323</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.250380</td>\n",
       "      <td>2.332515</td>\n",
       "      <td>0.397646</td>\n",
       "      <td>6.850616</td>\n",
       "      <td>-4.855162</td>\n",
       "      <td>1.951569</td>\n",
       "      <td>0.518806</td>\n",
       "      <td>1.831608</td>\n",
       "      <td>3.101244</td>\n",
       "      <td>0.969221</td>\n",
       "      <td>...</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>-46.375080</td>\n",
       "      <td>325.845907</td>\n",
       "      <td>-68.579427</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1516</td>\n",
       "      <td>0.1900</td>\n",
       "      <td>0.0104</td>\n",
       "      <td>39.8317</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.865322</td>\n",
       "      <td>18.889302</td>\n",
       "      <td>0.621161</td>\n",
       "      <td>98.295471</td>\n",
       "      <td>-4.709099</td>\n",
       "      <td>2.236805</td>\n",
       "      <td>0.578331</td>\n",
       "      <td>2.121090</td>\n",
       "      <td>3.606390</td>\n",
       "      <td>1.182853</td>\n",
       "      <td>...</td>\n",
       "      <td>346.500000</td>\n",
       "      <td>-62.320400</td>\n",
       "      <td>321.951129</td>\n",
       "      <td>-50.736054</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1695</td>\n",
       "      <td>0.5409</td>\n",
       "      <td>0.2283</td>\n",
       "      <td>42.4667</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.731255</td>\n",
       "      <td>14.382791</td>\n",
       "      <td>0.051684</td>\n",
       "      <td>98.330528</td>\n",
       "      <td>-6.794837</td>\n",
       "      <td>2.459034</td>\n",
       "      <td>0.512695</td>\n",
       "      <td>2.372941</td>\n",
       "      <td>3.750592</td>\n",
       "      <td>1.529222</td>\n",
       "      <td>...</td>\n",
       "      <td>346.655182</td>\n",
       "      <td>-63.260487</td>\n",
       "      <td>320.952196</td>\n",
       "      <td>-50.040935</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.543690</td>\n",
       "      <td>2.971154</td>\n",
       "      <td>-0.701125</td>\n",
       "      <td>9.575159</td>\n",
       "      <td>-8.199913</td>\n",
       "      <td>2.583985</td>\n",
       "      <td>0.392040</td>\n",
       "      <td>2.525881</td>\n",
       "      <td>3.532003</td>\n",
       "      <td>1.790858</td>\n",
       "      <td>...</td>\n",
       "      <td>53.964844</td>\n",
       "      <td>-28.630989</td>\n",
       "      <td>225.142950</td>\n",
       "      <td>-53.813613</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.286018</td>\n",
       "      <td>3.329948</td>\n",
       "      <td>1.127859</td>\n",
       "      <td>16.806917</td>\n",
       "      <td>-5.714864</td>\n",
       "      <td>2.217633</td>\n",
       "      <td>0.558221</td>\n",
       "      <td>2.122150</td>\n",
       "      <td>3.618424</td>\n",
       "      <td>1.198989</td>\n",
       "      <td>...</td>\n",
       "      <td>352.398651</td>\n",
       "      <td>-62.696659</td>\n",
       "      <td>318.017427</td>\n",
       "      <td>-51.967966</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1469</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>39.2171</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.226462</td>\n",
       "      <td>2.035230</td>\n",
       "      <td>0.159748</td>\n",
       "      <td>3.738764</td>\n",
       "      <td>-4.278332</td>\n",
       "      <td>2.211076</td>\n",
       "      <td>0.557269</td>\n",
       "      <td>2.116915</td>\n",
       "      <td>3.595696</td>\n",
       "      <td>1.181996</td>\n",
       "      <td>...</td>\n",
       "      <td>346.130127</td>\n",
       "      <td>-63.072620</td>\n",
       "      <td>321.423103</td>\n",
       "      <td>-50.042305</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1069</td>\n",
       "      <td>0.1274</td>\n",
       "      <td>0.0198</td>\n",
       "      <td>38.8800</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.824972</td>\n",
       "      <td>6.510507</td>\n",
       "      <td>0.574138</td>\n",
       "      <td>27.857285</td>\n",
       "      <td>-4.159219</td>\n",
       "      <td>2.177344</td>\n",
       "      <td>0.615777</td>\n",
       "      <td>1.941345</td>\n",
       "      <td>3.308392</td>\n",
       "      <td>1.472333</td>\n",
       "      <td>...</td>\n",
       "      <td>150.820312</td>\n",
       "      <td>1.641510</td>\n",
       "      <td>237.994507</td>\n",
       "      <td>42.358984</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1610</td>\n",
       "      <td>0.1818</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>39.7258</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.091090</td>\n",
       "      <td>1.883022</td>\n",
       "      <td>0.154212</td>\n",
       "      <td>8.438391</td>\n",
       "      <td>-4.083338</td>\n",
       "      <td>1.977622</td>\n",
       "      <td>0.525491</td>\n",
       "      <td>1.857620</td>\n",
       "      <td>3.143507</td>\n",
       "      <td>0.978373</td>\n",
       "      <td>...</td>\n",
       "      <td>359.811707</td>\n",
       "      <td>-45.191612</td>\n",
       "      <td>329.485675</td>\n",
       "      <td>-69.150905</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0561</td>\n",
       "      <td>0.0556</td>\n",
       "      <td>0.0301</td>\n",
       "      <td>36.9750</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.322538</td>\n",
       "      <td>2.383290</td>\n",
       "      <td>0.637967</td>\n",
       "      <td>5.328613</td>\n",
       "      <td>-7.739589</td>\n",
       "      <td>2.096117</td>\n",
       "      <td>0.508165</td>\n",
       "      <td>1.997268</td>\n",
       "      <td>3.244135</td>\n",
       "      <td>1.157291</td>\n",
       "      <td>...</td>\n",
       "      <td>2.097458</td>\n",
       "      <td>-45.783966</td>\n",
       "      <td>324.737840</td>\n",
       "      <td>-69.478613</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>31.680358</td>\n",
       "      <td>46.742926</td>\n",
       "      <td>10.032253</td>\n",
       "      <td>199.275742</td>\n",
       "      <td>-3.190367</td>\n",
       "      <td>2.331228</td>\n",
       "      <td>0.543016</td>\n",
       "      <td>2.349883</td>\n",
       "      <td>3.293644</td>\n",
       "      <td>1.627543</td>\n",
       "      <td>...</td>\n",
       "      <td>152.050781</td>\n",
       "      <td>3.284369</td>\n",
       "      <td>237.157374</td>\n",
       "      <td>44.318466</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5149</td>\n",
       "      <td>0.5512</td>\n",
       "      <td>0.0221</td>\n",
       "      <td>42.5158</td>\n",
       "      <td>0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>31.302265</td>\n",
       "      <td>127.540028</td>\n",
       "      <td>0.401583</td>\n",
       "      <td>775.901978</td>\n",
       "      <td>-6.347747</td>\n",
       "      <td>2.109742</td>\n",
       "      <td>0.804010</td>\n",
       "      <td>1.928584</td>\n",
       "      <td>5.566474</td>\n",
       "      <td>0.966414</td>\n",
       "      <td>...</td>\n",
       "      <td>358.648071</td>\n",
       "      <td>-46.375080</td>\n",
       "      <td>329.462659</td>\n",
       "      <td>-67.716008</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1197</td>\n",
       "      <td>0.1322</td>\n",
       "      <td>0.3351</td>\n",
       "      <td>38.9679</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.971631</td>\n",
       "      <td>2.351733</td>\n",
       "      <td>0.968820</td>\n",
       "      <td>9.007335</td>\n",
       "      <td>-2.773278</td>\n",
       "      <td>2.138384</td>\n",
       "      <td>0.604311</td>\n",
       "      <td>1.904409</td>\n",
       "      <td>3.285769</td>\n",
       "      <td>1.450324</td>\n",
       "      <td>...</td>\n",
       "      <td>151.699219</td>\n",
       "      <td>3.583322</td>\n",
       "      <td>236.533224</td>\n",
       "      <td>44.205648</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2333</td>\n",
       "      <td>0.2205</td>\n",
       "      <td>0.9667</td>\n",
       "      <td>40.1939</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4.651881</td>\n",
       "      <td>11.842776</td>\n",
       "      <td>0.110946</td>\n",
       "      <td>45.106499</td>\n",
       "      <td>-8.825118</td>\n",
       "      <td>2.215408</td>\n",
       "      <td>0.562842</td>\n",
       "      <td>2.107961</td>\n",
       "      <td>3.587826</td>\n",
       "      <td>1.182470</td>\n",
       "      <td>...</td>\n",
       "      <td>349.615387</td>\n",
       "      <td>-63.636005</td>\n",
       "      <td>318.927246</td>\n",
       "      <td>-50.506542</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5919</td>\n",
       "      <td>0.5995</td>\n",
       "      <td>0.0127</td>\n",
       "      <td>42.7370</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.765084</td>\n",
       "      <td>5.177720</td>\n",
       "      <td>0.658242</td>\n",
       "      <td>26.796335</td>\n",
       "      <td>-6.204014</td>\n",
       "      <td>2.041811</td>\n",
       "      <td>0.425448</td>\n",
       "      <td>1.998902</td>\n",
       "      <td>3.066065</td>\n",
       "      <td>1.121560</td>\n",
       "      <td>...</td>\n",
       "      <td>33.222656</td>\n",
       "      <td>-4.780192</td>\n",
       "      <td>167.515653</td>\n",
       "      <td>-60.396584</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3201</td>\n",
       "      <td>0.2685</td>\n",
       "      <td>0.5211</td>\n",
       "      <td>40.6793</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.056887</td>\n",
       "      <td>7.248909</td>\n",
       "      <td>-0.173963</td>\n",
       "      <td>49.394707</td>\n",
       "      <td>-6.526413</td>\n",
       "      <td>2.003158</td>\n",
       "      <td>0.526943</td>\n",
       "      <td>1.884593</td>\n",
       "      <td>3.167629</td>\n",
       "      <td>1.004549</td>\n",
       "      <td>...</td>\n",
       "      <td>0.929752</td>\n",
       "      <td>-44.597992</td>\n",
       "      <td>328.531426</td>\n",
       "      <td>-70.083244</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.335973</td>\n",
       "      <td>2.202072</td>\n",
       "      <td>0.198999</td>\n",
       "      <td>6.253617</td>\n",
       "      <td>-5.223898</td>\n",
       "      <td>2.054741</td>\n",
       "      <td>0.425070</td>\n",
       "      <td>2.015447</td>\n",
       "      <td>3.100387</td>\n",
       "      <td>1.139080</td>\n",
       "      <td>...</td>\n",
       "      <td>34.277344</td>\n",
       "      <td>-5.679190</td>\n",
       "      <td>170.314930</td>\n",
       "      <td>-60.410322</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5680</td>\n",
       "      <td>0.5667</td>\n",
       "      <td>0.0181</td>\n",
       "      <td>42.5888</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>82.591718</td>\n",
       "      <td>219.449539</td>\n",
       "      <td>0.936554</td>\n",
       "      <td>885.824158</td>\n",
       "      <td>-4.082807</td>\n",
       "      <td>2.283663</td>\n",
       "      <td>1.073158</td>\n",
       "      <td>1.994101</td>\n",
       "      <td>5.982180</td>\n",
       "      <td>0.958620</td>\n",
       "      <td>...</td>\n",
       "      <td>52.207031</td>\n",
       "      <td>-28.291550</td>\n",
       "      <td>224.208534</td>\n",
       "      <td>-55.300157</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0826</td>\n",
       "      <td>0.0850</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>37.9414</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.541591</td>\n",
       "      <td>2.291696</td>\n",
       "      <td>0.537307</td>\n",
       "      <td>7.082586</td>\n",
       "      <td>-6.513540</td>\n",
       "      <td>2.381178</td>\n",
       "      <td>0.527476</td>\n",
       "      <td>2.296527</td>\n",
       "      <td>3.725926</td>\n",
       "      <td>1.428517</td>\n",
       "      <td>...</td>\n",
       "      <td>352.398651</td>\n",
       "      <td>-62.696659</td>\n",
       "      <td>318.017427</td>\n",
       "      <td>-51.967966</td>\n",
       "      <td>1</td>\n",
       "      <td>3.4451</td>\n",
       "      <td>0.5176</td>\n",
       "      <td>1.2609</td>\n",
       "      <td>42.3516</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.439715</td>\n",
       "      <td>2.746728</td>\n",
       "      <td>-0.316380</td>\n",
       "      <td>8.846499</td>\n",
       "      <td>-7.704670</td>\n",
       "      <td>2.088997</td>\n",
       "      <td>0.505486</td>\n",
       "      <td>1.985378</td>\n",
       "      <td>3.225785</td>\n",
       "      <td>1.142539</td>\n",
       "      <td>...</td>\n",
       "      <td>359.446716</td>\n",
       "      <td>-44.201530</td>\n",
       "      <td>331.730015</td>\n",
       "      <td>-69.805709</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.152279</td>\n",
       "      <td>2.117315</td>\n",
       "      <td>-0.053894</td>\n",
       "      <td>3.330988</td>\n",
       "      <td>-6.646290</td>\n",
       "      <td>2.193894</td>\n",
       "      <td>0.552963</td>\n",
       "      <td>2.100861</td>\n",
       "      <td>3.569557</td>\n",
       "      <td>1.174578</td>\n",
       "      <td>...</td>\n",
       "      <td>347.013428</td>\n",
       "      <td>-62.508568</td>\n",
       "      <td>321.472056</td>\n",
       "      <td>-50.735330</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2628</td>\n",
       "      <td>0.1876</td>\n",
       "      <td>0.0216</td>\n",
       "      <td>39.8011</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.196311</td>\n",
       "      <td>1.913033</td>\n",
       "      <td>0.471618</td>\n",
       "      <td>6.864740</td>\n",
       "      <td>-4.701683</td>\n",
       "      <td>1.868053</td>\n",
       "      <td>0.457060</td>\n",
       "      <td>1.820069</td>\n",
       "      <td>2.999842</td>\n",
       "      <td>0.893490</td>\n",
       "      <td>...</td>\n",
       "      <td>53.085938</td>\n",
       "      <td>-28.122234</td>\n",
       "      <td>224.100909</td>\n",
       "      <td>-54.509752</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0830</td>\n",
       "      <td>0.0820</td>\n",
       "      <td>0.2257</td>\n",
       "      <td>37.8568</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.195455</td>\n",
       "      <td>5.099229</td>\n",
       "      <td>0.177877</td>\n",
       "      <td>23.977371</td>\n",
       "      <td>-5.379608</td>\n",
       "      <td>1.987518</td>\n",
       "      <td>0.522424</td>\n",
       "      <td>1.863150</td>\n",
       "      <td>3.160318</td>\n",
       "      <td>0.974567</td>\n",
       "      <td>...</td>\n",
       "      <td>1.694561</td>\n",
       "      <td>-45.191612</td>\n",
       "      <td>326.278557</td>\n",
       "      <td>-69.858253</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3779</td>\n",
       "      <td>0.4808</td>\n",
       "      <td>0.2970</td>\n",
       "      <td>42.1592</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>17.909620</td>\n",
       "      <td>109.875308</td>\n",
       "      <td>0.530420</td>\n",
       "      <td>920.117798</td>\n",
       "      <td>-4.271995</td>\n",
       "      <td>2.255444</td>\n",
       "      <td>0.686098</td>\n",
       "      <td>2.141656</td>\n",
       "      <td>6.900321</td>\n",
       "      <td>1.293009</td>\n",
       "      <td>...</td>\n",
       "      <td>32.695312</td>\n",
       "      <td>-4.929937</td>\n",
       "      <td>166.868469</td>\n",
       "      <td>-60.841230</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5620</th>\n",
       "      <td>2.054770</td>\n",
       "      <td>14.901965</td>\n",
       "      <td>5.938574</td>\n",
       "      <td>24.129116</td>\n",
       "      <td>-24.576620</td>\n",
       "      <td>14.000624</td>\n",
       "      <td>3.208598</td>\n",
       "      <td>13.432125</td>\n",
       "      <td>19.496635</td>\n",
       "      <td>8.190953</td>\n",
       "      <td>...</td>\n",
       "      <td>106.875000</td>\n",
       "      <td>-39.257931</td>\n",
       "      <td>250.208713</td>\n",
       "      <td>-13.903969</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5621</th>\n",
       "      <td>70.357405</td>\n",
       "      <td>75.431150</td>\n",
       "      <td>64.577019</td>\n",
       "      <td>179.664871</td>\n",
       "      <td>-79.481033</td>\n",
       "      <td>20.254783</td>\n",
       "      <td>3.357459</td>\n",
       "      <td>21.434834</td>\n",
       "      <td>25.289867</td>\n",
       "      <td>14.251978</td>\n",
       "      <td>...</td>\n",
       "      <td>169.453125</td>\n",
       "      <td>-13.094776</td>\n",
       "      <td>270.511916</td>\n",
       "      <td>43.804856</td>\n",
       "      <td>0</td>\n",
       "      <td>1.1221</td>\n",
       "      <td>1.8498</td>\n",
       "      <td>0.2668</td>\n",
       "      <td>45.7494</td>\n",
       "      <td>0.056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5622</th>\n",
       "      <td>65.542747</td>\n",
       "      <td>91.295286</td>\n",
       "      <td>64.066025</td>\n",
       "      <td>218.768768</td>\n",
       "      <td>-128.922348</td>\n",
       "      <td>105.985290</td>\n",
       "      <td>36.553314</td>\n",
       "      <td>101.321411</td>\n",
       "      <td>150.707504</td>\n",
       "      <td>60.083290</td>\n",
       "      <td>...</td>\n",
       "      <td>141.660004</td>\n",
       "      <td>-43.008633</td>\n",
       "      <td>268.001963</td>\n",
       "      <td>5.553252</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1331</td>\n",
       "      <td>0.1220</td>\n",
       "      <td>0.6970</td>\n",
       "      <td>38.7780</td>\n",
       "      <td>0.616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5623</th>\n",
       "      <td>-30.857168</td>\n",
       "      <td>68.852561</td>\n",
       "      <td>-21.583468</td>\n",
       "      <td>37.660698</td>\n",
       "      <td>-256.890076</td>\n",
       "      <td>28.447960</td>\n",
       "      <td>4.716523</td>\n",
       "      <td>30.751083</td>\n",
       "      <td>32.891907</td>\n",
       "      <td>20.016283</td>\n",
       "      <td>...</td>\n",
       "      <td>31.041668</td>\n",
       "      <td>-49.702389</td>\n",
       "      <td>276.078712</td>\n",
       "      <td>-63.462614</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5624</th>\n",
       "      <td>2.146311</td>\n",
       "      <td>16.168339</td>\n",
       "      <td>0.228895</td>\n",
       "      <td>47.165833</td>\n",
       "      <td>-23.628527</td>\n",
       "      <td>10.013092</td>\n",
       "      <td>3.221184</td>\n",
       "      <td>8.690401</td>\n",
       "      <td>15.737935</td>\n",
       "      <td>5.039326</td>\n",
       "      <td>...</td>\n",
       "      <td>306.035858</td>\n",
       "      <td>-42.809296</td>\n",
       "      <td>357.879735</td>\n",
       "      <td>-34.529521</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1938</td>\n",
       "      <td>0.4177</td>\n",
       "      <td>0.7828</td>\n",
       "      <td>41.7959</td>\n",
       "      <td>0.041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5625</th>\n",
       "      <td>1.791278</td>\n",
       "      <td>15.093451</td>\n",
       "      <td>-2.407559</td>\n",
       "      <td>41.623413</td>\n",
       "      <td>-15.591936</td>\n",
       "      <td>9.894688</td>\n",
       "      <td>3.194999</td>\n",
       "      <td>9.341228</td>\n",
       "      <td>15.680943</td>\n",
       "      <td>5.206946</td>\n",
       "      <td>...</td>\n",
       "      <td>77.695312</td>\n",
       "      <td>-16.801838</td>\n",
       "      <td>217.659075</td>\n",
       "      <td>-29.609584</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2024</td>\n",
       "      <td>0.5218</td>\n",
       "      <td>0.1283</td>\n",
       "      <td>42.3724</td>\n",
       "      <td>0.052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5626</th>\n",
       "      <td>5.817066</td>\n",
       "      <td>11.752964</td>\n",
       "      <td>3.802398</td>\n",
       "      <td>32.712036</td>\n",
       "      <td>-9.151092</td>\n",
       "      <td>9.664327</td>\n",
       "      <td>2.668093</td>\n",
       "      <td>9.465723</td>\n",
       "      <td>13.643835</td>\n",
       "      <td>5.945492</td>\n",
       "      <td>...</td>\n",
       "      <td>355.163544</td>\n",
       "      <td>-50.091457</td>\n",
       "      <td>328.699808</td>\n",
       "      <td>-63.346833</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5627</th>\n",
       "      <td>1.465725</td>\n",
       "      <td>6.619212</td>\n",
       "      <td>0.867030</td>\n",
       "      <td>12.320279</td>\n",
       "      <td>-10.919798</td>\n",
       "      <td>8.410145</td>\n",
       "      <td>2.649586</td>\n",
       "      <td>7.943666</td>\n",
       "      <td>12.492223</td>\n",
       "      <td>4.504568</td>\n",
       "      <td>...</td>\n",
       "      <td>22.851562</td>\n",
       "      <td>-18.681826</td>\n",
       "      <td>172.442571</td>\n",
       "      <td>-77.518364</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0949</td>\n",
       "      <td>0.1656</td>\n",
       "      <td>0.0257</td>\n",
       "      <td>39.5014</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5628</th>\n",
       "      <td>-1.951883</td>\n",
       "      <td>17.990129</td>\n",
       "      <td>2.209769</td>\n",
       "      <td>22.927462</td>\n",
       "      <td>-34.994026</td>\n",
       "      <td>16.664724</td>\n",
       "      <td>4.415450</td>\n",
       "      <td>16.780830</td>\n",
       "      <td>23.001982</td>\n",
       "      <td>7.895731</td>\n",
       "      <td>...</td>\n",
       "      <td>86.132812</td>\n",
       "      <td>-13.708317</td>\n",
       "      <td>218.054844</td>\n",
       "      <td>-20.910333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2456</td>\n",
       "      <td>0.3015</td>\n",
       "      <td>0.0576</td>\n",
       "      <td>40.9681</td>\n",
       "      <td>0.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5629</th>\n",
       "      <td>-124.638962</td>\n",
       "      <td>237.136284</td>\n",
       "      <td>-27.746625</td>\n",
       "      <td>18.858725</td>\n",
       "      <td>-698.741272</td>\n",
       "      <td>29.903669</td>\n",
       "      <td>4.453258</td>\n",
       "      <td>29.992343</td>\n",
       "      <td>38.448170</td>\n",
       "      <td>25.025402</td>\n",
       "      <td>...</td>\n",
       "      <td>133.242188</td>\n",
       "      <td>-24.788561</td>\n",
       "      <td>249.573365</td>\n",
       "      <td>12.560887</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5630</th>\n",
       "      <td>2.553962</td>\n",
       "      <td>8.483883</td>\n",
       "      <td>3.126744</td>\n",
       "      <td>12.323429</td>\n",
       "      <td>-15.497592</td>\n",
       "      <td>9.844305</td>\n",
       "      <td>2.590592</td>\n",
       "      <td>9.855156</td>\n",
       "      <td>13.928055</td>\n",
       "      <td>5.081168</td>\n",
       "      <td>...</td>\n",
       "      <td>11.074219</td>\n",
       "      <td>-8.084014</td>\n",
       "      <td>117.528357</td>\n",
       "      <td>-70.880802</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0760</td>\n",
       "      <td>0.0686</td>\n",
       "      <td>0.0194</td>\n",
       "      <td>37.4496</td>\n",
       "      <td>0.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5631</th>\n",
       "      <td>4.304134</td>\n",
       "      <td>7.991223</td>\n",
       "      <td>3.920901</td>\n",
       "      <td>15.796138</td>\n",
       "      <td>-9.347571</td>\n",
       "      <td>9.800671</td>\n",
       "      <td>2.013052</td>\n",
       "      <td>9.737120</td>\n",
       "      <td>13.558089</td>\n",
       "      <td>6.621549</td>\n",
       "      <td>...</td>\n",
       "      <td>340.839844</td>\n",
       "      <td>-32.442867</td>\n",
       "      <td>14.265035</td>\n",
       "      <td>-61.816065</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5632</th>\n",
       "      <td>-3.684875</td>\n",
       "      <td>23.835349</td>\n",
       "      <td>-1.809323</td>\n",
       "      <td>35.988598</td>\n",
       "      <td>-50.946960</td>\n",
       "      <td>38.588183</td>\n",
       "      <td>12.339204</td>\n",
       "      <td>35.144260</td>\n",
       "      <td>63.169582</td>\n",
       "      <td>22.520668</td>\n",
       "      <td>...</td>\n",
       "      <td>138.164062</td>\n",
       "      <td>-40.033035</td>\n",
       "      <td>264.026219</td>\n",
       "      <td>5.768998</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0397</td>\n",
       "      <td>0.0768</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>37.7087</td>\n",
       "      <td>0.417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5633</th>\n",
       "      <td>7.941816</td>\n",
       "      <td>18.133961</td>\n",
       "      <td>4.148020</td>\n",
       "      <td>56.430172</td>\n",
       "      <td>-19.579592</td>\n",
       "      <td>8.053082</td>\n",
       "      <td>2.155172</td>\n",
       "      <td>7.503466</td>\n",
       "      <td>11.871939</td>\n",
       "      <td>4.973414</td>\n",
       "      <td>...</td>\n",
       "      <td>28.828125</td>\n",
       "      <td>-25.117701</td>\n",
       "      <td>208.535318</td>\n",
       "      <td>-75.532469</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5634</th>\n",
       "      <td>4.952017</td>\n",
       "      <td>6.296417</td>\n",
       "      <td>3.307438</td>\n",
       "      <td>17.031120</td>\n",
       "      <td>-0.727187</td>\n",
       "      <td>9.416829</td>\n",
       "      <td>3.330285</td>\n",
       "      <td>9.019597</td>\n",
       "      <td>14.271378</td>\n",
       "      <td>4.807910</td>\n",
       "      <td>...</td>\n",
       "      <td>140.976562</td>\n",
       "      <td>3.732834</td>\n",
       "      <td>228.783975</td>\n",
       "      <td>35.301875</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1518</td>\n",
       "      <td>0.1798</td>\n",
       "      <td>0.0301</td>\n",
       "      <td>39.6994</td>\n",
       "      <td>0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5635</th>\n",
       "      <td>6.631107</td>\n",
       "      <td>24.874826</td>\n",
       "      <td>3.425639</td>\n",
       "      <td>70.444618</td>\n",
       "      <td>-26.629921</td>\n",
       "      <td>19.060711</td>\n",
       "      <td>2.869418</td>\n",
       "      <td>19.266908</td>\n",
       "      <td>24.095707</td>\n",
       "      <td>13.701665</td>\n",
       "      <td>...</td>\n",
       "      <td>314.296875</td>\n",
       "      <td>-40.033035</td>\n",
       "      <td>2.071417</td>\n",
       "      <td>-40.445067</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5636</th>\n",
       "      <td>2.405129</td>\n",
       "      <td>8.650150</td>\n",
       "      <td>3.151900</td>\n",
       "      <td>14.506971</td>\n",
       "      <td>-17.250694</td>\n",
       "      <td>10.635252</td>\n",
       "      <td>3.206649</td>\n",
       "      <td>11.213476</td>\n",
       "      <td>16.030832</td>\n",
       "      <td>6.174638</td>\n",
       "      <td>...</td>\n",
       "      <td>54.316406</td>\n",
       "      <td>-18.524391</td>\n",
       "      <td>209.170030</td>\n",
       "      <td>-51.015495</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1226</td>\n",
       "      <td>0.1440</td>\n",
       "      <td>0.0172</td>\n",
       "      <td>39.1698</td>\n",
       "      <td>0.061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5637</th>\n",
       "      <td>76.695005</td>\n",
       "      <td>181.571121</td>\n",
       "      <td>6.474941</td>\n",
       "      <td>522.236511</td>\n",
       "      <td>-17.358896</td>\n",
       "      <td>11.012676</td>\n",
       "      <td>3.477366</td>\n",
       "      <td>9.834426</td>\n",
       "      <td>19.544893</td>\n",
       "      <td>7.174377</td>\n",
       "      <td>...</td>\n",
       "      <td>304.980469</td>\n",
       "      <td>-14.169522</td>\n",
       "      <td>29.658085</td>\n",
       "      <td>-25.884722</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2094</td>\n",
       "      <td>0.2023</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>39.9839</td>\n",
       "      <td>0.061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5638</th>\n",
       "      <td>-0.865699</td>\n",
       "      <td>5.275708</td>\n",
       "      <td>-1.792765</td>\n",
       "      <td>8.772192</td>\n",
       "      <td>-9.656919</td>\n",
       "      <td>8.049397</td>\n",
       "      <td>2.941270</td>\n",
       "      <td>7.990155</td>\n",
       "      <td>12.815311</td>\n",
       "      <td>4.617105</td>\n",
       "      <td>...</td>\n",
       "      <td>132.539062</td>\n",
       "      <td>-1.641510</td>\n",
       "      <td>229.063354</td>\n",
       "      <td>25.304821</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5639</th>\n",
       "      <td>0.251681</td>\n",
       "      <td>13.768539</td>\n",
       "      <td>4.693686</td>\n",
       "      <td>16.854452</td>\n",
       "      <td>-28.645819</td>\n",
       "      <td>9.799521</td>\n",
       "      <td>3.259856</td>\n",
       "      <td>10.826016</td>\n",
       "      <td>15.085577</td>\n",
       "      <td>5.092716</td>\n",
       "      <td>...</td>\n",
       "      <td>164.003906</td>\n",
       "      <td>-31.039240</td>\n",
       "      <td>275.630181</td>\n",
       "      <td>25.642742</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2760</td>\n",
       "      <td>0.2847</td>\n",
       "      <td>0.0109</td>\n",
       "      <td>40.8250</td>\n",
       "      <td>0.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5640</th>\n",
       "      <td>1.149271</td>\n",
       "      <td>6.668391</td>\n",
       "      <td>0.976481</td>\n",
       "      <td>11.842884</td>\n",
       "      <td>-8.251876</td>\n",
       "      <td>9.304400</td>\n",
       "      <td>1.778143</td>\n",
       "      <td>9.329457</td>\n",
       "      <td>11.740060</td>\n",
       "      <td>7.241809</td>\n",
       "      <td>...</td>\n",
       "      <td>174.902344</td>\n",
       "      <td>-2.089372</td>\n",
       "      <td>269.456940</td>\n",
       "      <td>56.041993</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4215</td>\n",
       "      <td>0.3775</td>\n",
       "      <td>0.0206</td>\n",
       "      <td>41.5364</td>\n",
       "      <td>0.024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5641</th>\n",
       "      <td>-0.372498</td>\n",
       "      <td>7.461610</td>\n",
       "      <td>1.733515</td>\n",
       "      <td>8.729843</td>\n",
       "      <td>-14.405594</td>\n",
       "      <td>9.185439</td>\n",
       "      <td>3.362048</td>\n",
       "      <td>9.720994</td>\n",
       "      <td>14.303882</td>\n",
       "      <td>4.066229</td>\n",
       "      <td>...</td>\n",
       "      <td>142.734375</td>\n",
       "      <td>-23.480536</td>\n",
       "      <td>254.430952</td>\n",
       "      <td>19.977762</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0584</td>\n",
       "      <td>0.0885</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>38.0319</td>\n",
       "      <td>0.056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5642</th>\n",
       "      <td>68.017035</td>\n",
       "      <td>121.996538</td>\n",
       "      <td>5.394745</td>\n",
       "      <td>322.911011</td>\n",
       "      <td>-20.284691</td>\n",
       "      <td>10.052108</td>\n",
       "      <td>3.869097</td>\n",
       "      <td>8.203415</td>\n",
       "      <td>17.857975</td>\n",
       "      <td>6.013713</td>\n",
       "      <td>...</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>-20.264481</td>\n",
       "      <td>226.045011</td>\n",
       "      <td>-20.105392</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1273</td>\n",
       "      <td>2.6113</td>\n",
       "      <td>0.9733</td>\n",
       "      <td>46.6624</td>\n",
       "      <td>0.043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5643</th>\n",
       "      <td>3.520001</td>\n",
       "      <td>7.112679</td>\n",
       "      <td>4.258116</td>\n",
       "      <td>15.379319</td>\n",
       "      <td>-9.616444</td>\n",
       "      <td>8.068615</td>\n",
       "      <td>1.747057</td>\n",
       "      <td>7.523541</td>\n",
       "      <td>11.939057</td>\n",
       "      <td>6.026685</td>\n",
       "      <td>...</td>\n",
       "      <td>142.734375</td>\n",
       "      <td>-18.997131</td>\n",
       "      <td>250.892051</td>\n",
       "      <td>23.021357</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0591</td>\n",
       "      <td>0.0569</td>\n",
       "      <td>0.0248</td>\n",
       "      <td>37.0254</td>\n",
       "      <td>0.045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5644</th>\n",
       "      <td>11.090273</td>\n",
       "      <td>31.475195</td>\n",
       "      <td>8.730617</td>\n",
       "      <td>101.819145</td>\n",
       "      <td>-17.687801</td>\n",
       "      <td>28.387694</td>\n",
       "      <td>7.461073</td>\n",
       "      <td>27.410282</td>\n",
       "      <td>45.300827</td>\n",
       "      <td>17.767962</td>\n",
       "      <td>...</td>\n",
       "      <td>294.960938</td>\n",
       "      <td>-4.031936</td>\n",
       "      <td>34.856817</td>\n",
       "      <td>-12.602145</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5645</th>\n",
       "      <td>1.286655</td>\n",
       "      <td>15.998517</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>51.247578</td>\n",
       "      <td>-23.468113</td>\n",
       "      <td>8.770909</td>\n",
       "      <td>2.541784</td>\n",
       "      <td>8.903850</td>\n",
       "      <td>13.049633</td>\n",
       "      <td>5.329577</td>\n",
       "      <td>...</td>\n",
       "      <td>26.718750</td>\n",
       "      <td>-14.940303</td>\n",
       "      <td>172.342697</td>\n",
       "      <td>-72.255675</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5646</th>\n",
       "      <td>24.635243</td>\n",
       "      <td>79.713932</td>\n",
       "      <td>3.523321</td>\n",
       "      <td>271.930481</td>\n",
       "      <td>-22.168346</td>\n",
       "      <td>15.157640</td>\n",
       "      <td>5.369079</td>\n",
       "      <td>15.873405</td>\n",
       "      <td>24.077696</td>\n",
       "      <td>7.560100</td>\n",
       "      <td>...</td>\n",
       "      <td>120.101349</td>\n",
       "      <td>-62.696659</td>\n",
       "      <td>275.742955</td>\n",
       "      <td>-16.509746</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1725</td>\n",
       "      <td>2.5606</td>\n",
       "      <td>1.1146</td>\n",
       "      <td>46.6108</td>\n",
       "      <td>0.136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5647</th>\n",
       "      <td>-0.282914</td>\n",
       "      <td>46.605187</td>\n",
       "      <td>7.376702</td>\n",
       "      <td>52.152622</td>\n",
       "      <td>-135.602631</td>\n",
       "      <td>57.640948</td>\n",
       "      <td>16.719177</td>\n",
       "      <td>61.334496</td>\n",
       "      <td>79.265930</td>\n",
       "      <td>27.798227</td>\n",
       "      <td>...</td>\n",
       "      <td>203.108109</td>\n",
       "      <td>-55.682144</td>\n",
       "      <td>308.728904</td>\n",
       "      <td>6.727511</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5648</th>\n",
       "      <td>3.374208</td>\n",
       "      <td>14.420201</td>\n",
       "      <td>-1.682394</td>\n",
       "      <td>37.959984</td>\n",
       "      <td>-11.813696</td>\n",
       "      <td>9.850851</td>\n",
       "      <td>3.139314</td>\n",
       "      <td>9.837847</td>\n",
       "      <td>15.302673</td>\n",
       "      <td>5.044760</td>\n",
       "      <td>...</td>\n",
       "      <td>79.101562</td>\n",
       "      <td>-35.501846</td>\n",
       "      <td>239.172243</td>\n",
       "      <td>-33.827844</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5649</th>\n",
       "      <td>812.700937</td>\n",
       "      <td>2120.766511</td>\n",
       "      <td>90.714111</td>\n",
       "      <td>7761.321777</td>\n",
       "      <td>-41.214264</td>\n",
       "      <td>60.686820</td>\n",
       "      <td>33.270562</td>\n",
       "      <td>57.096981</td>\n",
       "      <td>167.561752</td>\n",
       "      <td>38.742641</td>\n",
       "      <td>...</td>\n",
       "      <td>301.992188</td>\n",
       "      <td>-17.426323</td>\n",
       "      <td>25.102988</td>\n",
       "      <td>-24.511101</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5650 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      flux_mean0    flux_std0  flux_median0    flux_max0   flux_min0  \\\n",
       "0      -3.254554    83.944735    -10.015225   125.182808 -116.913223   \n",
       "1       1.797523     4.374445      1.056714    18.014029   -3.874349   \n",
       "2       0.660948     2.360084      0.581027     5.330927   -6.804703   \n",
       "3      14.888847    52.335031      0.361674   276.159576   -7.049055   \n",
       "4       0.107645     2.100048     -0.258138     5.241472   -3.751457   \n",
       "5       2.225061     6.770588      0.631169    22.368912   -3.560047   \n",
       "6       0.658652     2.860190      0.246219     7.164557   -7.061294   \n",
       "7       0.250380     2.332515      0.397646     6.850616   -4.855162   \n",
       "8       4.865322    18.889302      0.621161    98.295471   -4.709099   \n",
       "9       2.731255    14.382791      0.051684    98.330528   -6.794837   \n",
       "10     -0.543690     2.971154     -0.701125     9.575159   -8.199913   \n",
       "11      1.286018     3.329948      1.127859    16.806917   -5.714864   \n",
       "12      0.226462     2.035230      0.159748     3.738764   -4.278332   \n",
       "13      1.824972     6.510507      0.574138    27.857285   -4.159219   \n",
       "14      0.091090     1.883022      0.154212     8.438391   -4.083338   \n",
       "15      0.322538     2.383290      0.637967     5.328613   -7.739589   \n",
       "16     31.680358    46.742926     10.032253   199.275742   -3.190367   \n",
       "17     31.302265   127.540028      0.401583   775.901978   -6.347747   \n",
       "18      0.971631     2.351733      0.968820     9.007335   -2.773278   \n",
       "19      4.651881    11.842776      0.110946    45.106499   -8.825118   \n",
       "20      1.765084     5.177720      0.658242    26.796335   -6.204014   \n",
       "21      1.056887     7.248909     -0.173963    49.394707   -6.526413   \n",
       "22      0.335973     2.202072      0.198999     6.253617   -5.223898   \n",
       "23     82.591718   219.449539      0.936554   885.824158   -4.082807   \n",
       "24      0.541591     2.291696      0.537307     7.082586   -6.513540   \n",
       "25     -0.439715     2.746728     -0.316380     8.846499   -7.704670   \n",
       "26     -0.152279     2.117315     -0.053894     3.330988   -6.646290   \n",
       "27      0.196311     1.913033      0.471618     6.864740   -4.701683   \n",
       "28      1.195455     5.099229      0.177877    23.977371   -5.379608   \n",
       "29     17.909620   109.875308      0.530420   920.117798   -4.271995   \n",
       "...          ...          ...           ...          ...         ...   \n",
       "5620    2.054770    14.901965      5.938574    24.129116  -24.576620   \n",
       "5621   70.357405    75.431150     64.577019   179.664871  -79.481033   \n",
       "5622   65.542747    91.295286     64.066025   218.768768 -128.922348   \n",
       "5623  -30.857168    68.852561    -21.583468    37.660698 -256.890076   \n",
       "5624    2.146311    16.168339      0.228895    47.165833  -23.628527   \n",
       "5625    1.791278    15.093451     -2.407559    41.623413  -15.591936   \n",
       "5626    5.817066    11.752964      3.802398    32.712036   -9.151092   \n",
       "5627    1.465725     6.619212      0.867030    12.320279  -10.919798   \n",
       "5628   -1.951883    17.990129      2.209769    22.927462  -34.994026   \n",
       "5629 -124.638962   237.136284    -27.746625    18.858725 -698.741272   \n",
       "5630    2.553962     8.483883      3.126744    12.323429  -15.497592   \n",
       "5631    4.304134     7.991223      3.920901    15.796138   -9.347571   \n",
       "5632   -3.684875    23.835349     -1.809323    35.988598  -50.946960   \n",
       "5633    7.941816    18.133961      4.148020    56.430172  -19.579592   \n",
       "5634    4.952017     6.296417      3.307438    17.031120   -0.727187   \n",
       "5635    6.631107    24.874826      3.425639    70.444618  -26.629921   \n",
       "5636    2.405129     8.650150      3.151900    14.506971  -17.250694   \n",
       "5637   76.695005   181.571121      6.474941   522.236511  -17.358896   \n",
       "5638   -0.865699     5.275708     -1.792765     8.772192   -9.656919   \n",
       "5639    0.251681    13.768539      4.693686    16.854452  -28.645819   \n",
       "5640    1.149271     6.668391      0.976481    11.842884   -8.251876   \n",
       "5641   -0.372498     7.461610      1.733515     8.729843  -14.405594   \n",
       "5642   68.017035   121.996538      5.394745   322.911011  -20.284691   \n",
       "5643    3.520001     7.112679      4.258116    15.379319   -9.616444   \n",
       "5644   11.090273    31.475195      8.730617   101.819145  -17.687801   \n",
       "5645    1.286655    15.998517      0.566667    51.247578  -23.468113   \n",
       "5646   24.635243    79.713932      3.523321   271.930481  -22.168346   \n",
       "5647   -0.282914    46.605187      7.376702    52.152622 -135.602631   \n",
       "5648    3.374208    14.420201     -1.682394    37.959984  -11.813696   \n",
       "5649  812.700937  2120.766511     90.714111  7761.321777  -41.214264   \n",
       "\n",
       "      flux_err_mean0  flux_err_std0  flux_err_median0  flux_err_max0  \\\n",
       "0           3.823448       0.493621          3.866380       4.737393   \n",
       "1           1.954723       0.520573          1.877306       3.093587   \n",
       "2           2.251139       0.566168          2.153805       3.658313   \n",
       "3           2.292132       0.521717          2.243897       3.585604   \n",
       "4           2.223667       0.562132          2.128103       3.632440   \n",
       "5           2.244314       0.620582          2.045203       3.402587   \n",
       "6           2.221272       0.582866          1.997216       3.323257   \n",
       "7           1.951569       0.518806          1.831608       3.101244   \n",
       "8           2.236805       0.578331          2.121090       3.606390   \n",
       "9           2.459034       0.512695          2.372941       3.750592   \n",
       "10          2.583985       0.392040          2.525881       3.532003   \n",
       "11          2.217633       0.558221          2.122150       3.618424   \n",
       "12          2.211076       0.557269          2.116915       3.595696   \n",
       "13          2.177344       0.615777          1.941345       3.308392   \n",
       "14          1.977622       0.525491          1.857620       3.143507   \n",
       "15          2.096117       0.508165          1.997268       3.244135   \n",
       "16          2.331228       0.543016          2.349883       3.293644   \n",
       "17          2.109742       0.804010          1.928584       5.566474   \n",
       "18          2.138384       0.604311          1.904409       3.285769   \n",
       "19          2.215408       0.562842          2.107961       3.587826   \n",
       "20          2.041811       0.425448          1.998902       3.066065   \n",
       "21          2.003158       0.526943          1.884593       3.167629   \n",
       "22          2.054741       0.425070          2.015447       3.100387   \n",
       "23          2.283663       1.073158          1.994101       5.982180   \n",
       "24          2.381178       0.527476          2.296527       3.725926   \n",
       "25          2.088997       0.505486          1.985378       3.225785   \n",
       "26          2.193894       0.552963          2.100861       3.569557   \n",
       "27          1.868053       0.457060          1.820069       2.999842   \n",
       "28          1.987518       0.522424          1.863150       3.160318   \n",
       "29          2.255444       0.686098          2.141656       6.900321   \n",
       "...              ...            ...               ...            ...   \n",
       "5620       14.000624       3.208598         13.432125      19.496635   \n",
       "5621       20.254783       3.357459         21.434834      25.289867   \n",
       "5622      105.985290      36.553314        101.321411     150.707504   \n",
       "5623       28.447960       4.716523         30.751083      32.891907   \n",
       "5624       10.013092       3.221184          8.690401      15.737935   \n",
       "5625        9.894688       3.194999          9.341228      15.680943   \n",
       "5626        9.664327       2.668093          9.465723      13.643835   \n",
       "5627        8.410145       2.649586          7.943666      12.492223   \n",
       "5628       16.664724       4.415450         16.780830      23.001982   \n",
       "5629       29.903669       4.453258         29.992343      38.448170   \n",
       "5630        9.844305       2.590592          9.855156      13.928055   \n",
       "5631        9.800671       2.013052          9.737120      13.558089   \n",
       "5632       38.588183      12.339204         35.144260      63.169582   \n",
       "5633        8.053082       2.155172          7.503466      11.871939   \n",
       "5634        9.416829       3.330285          9.019597      14.271378   \n",
       "5635       19.060711       2.869418         19.266908      24.095707   \n",
       "5636       10.635252       3.206649         11.213476      16.030832   \n",
       "5637       11.012676       3.477366          9.834426      19.544893   \n",
       "5638        8.049397       2.941270          7.990155      12.815311   \n",
       "5639        9.799521       3.259856         10.826016      15.085577   \n",
       "5640        9.304400       1.778143          9.329457      11.740060   \n",
       "5641        9.185439       3.362048          9.720994      14.303882   \n",
       "5642       10.052108       3.869097          8.203415      17.857975   \n",
       "5643        8.068615       1.747057          7.523541      11.939057   \n",
       "5644       28.387694       7.461073         27.410282      45.300827   \n",
       "5645        8.770909       2.541784          8.903850      13.049633   \n",
       "5646       15.157640       5.369079         15.873405      24.077696   \n",
       "5647       57.640948      16.719177         61.334496      79.265930   \n",
       "5648        9.850851       3.139314          9.837847      15.302673   \n",
       "5649       60.686820      33.270562         57.096981     167.561752   \n",
       "\n",
       "      flux_err_min0  ...            ra       decl       gal_l      gal_b  ddf  \\\n",
       "0          2.844200  ...    349.046051 -61.943836  320.796530 -51.753706    1   \n",
       "1          0.957792  ...      0.189873 -45.586655  328.254458 -68.969298    1   \n",
       "2          1.208098  ...    352.711273 -63.823658  316.922299 -51.059403    1   \n",
       "3          1.333190  ...    347.846710 -64.760857  318.929827 -49.143596    1   \n",
       "4          1.193795  ...    348.595886 -63.072620  320.023289 -50.713060    1   \n",
       "5          1.514232  ...    149.414062   3.433834  234.919132  42.245550    1   \n",
       "6          1.565513  ...    149.414062   1.940072  236.565366  41.393323    1   \n",
       "7          0.969221  ...      0.965665 -46.375080  325.845907 -68.579427    1   \n",
       "8          1.182853  ...    346.500000 -62.320400  321.951129 -50.736054    1   \n",
       "9          1.529222  ...    346.655182 -63.260487  320.952196 -50.040935    1   \n",
       "10         1.790858  ...     53.964844 -28.630989  225.142950 -53.813613    1   \n",
       "11         1.198989  ...    352.398651 -62.696659  318.017427 -51.967966    1   \n",
       "12         1.181996  ...    346.130127 -63.072620  321.423103 -50.042305    1   \n",
       "13         1.472333  ...    150.820312   1.641510  237.994507  42.358984    1   \n",
       "14         0.978373  ...    359.811707 -45.191612  329.485675 -69.150905    1   \n",
       "15         1.157291  ...      2.097458 -45.783966  324.737840 -69.478613    1   \n",
       "16         1.627543  ...    152.050781   3.284369  237.157374  44.318466    1   \n",
       "17         0.966414  ...    358.648071 -46.375080  329.462659 -67.716008    1   \n",
       "18         1.450324  ...    151.699219   3.583322  236.533224  44.205648    1   \n",
       "19         1.182470  ...    349.615387 -63.636005  318.927246 -50.506542    1   \n",
       "20         1.121560  ...     33.222656  -4.780192  167.515653 -60.396584    1   \n",
       "21         1.004549  ...      0.929752 -44.597992  328.531426 -70.083244    1   \n",
       "22         1.139080  ...     34.277344  -5.679190  170.314930 -60.410322    1   \n",
       "23         0.958620  ...     52.207031 -28.291550  224.208534 -55.300157    1   \n",
       "24         1.428517  ...    352.398651 -62.696659  318.017427 -51.967966    1   \n",
       "25         1.142539  ...    359.446716 -44.201530  331.730015 -69.805709    1   \n",
       "26         1.174578  ...    347.013428 -62.508568  321.472056 -50.735330    1   \n",
       "27         0.893490  ...     53.085938 -28.122234  224.100909 -54.509752    1   \n",
       "28         0.974567  ...      1.694561 -45.191612  326.278557 -69.858253    1   \n",
       "29         1.293009  ...     32.695312  -4.929937  166.868469 -60.841230    1   \n",
       "...             ...  ...           ...        ...         ...        ...  ...   \n",
       "5620       8.190953  ...    106.875000 -39.257931  250.208713 -13.903969    0   \n",
       "5621      14.251978  ...    169.453125 -13.094776  270.511916  43.804856    0   \n",
       "5622      60.083290  ...    141.660004 -43.008633  268.001963   5.553252    0   \n",
       "5623      20.016283  ...     31.041668 -49.702389  276.078712 -63.462614    0   \n",
       "5624       5.039326  ...    306.035858 -42.809296  357.879735 -34.529521    0   \n",
       "5625       5.206946  ...     77.695312 -16.801838  217.659075 -29.609584    0   \n",
       "5626       5.945492  ...    355.163544 -50.091457  328.699808 -63.346833    0   \n",
       "5627       4.504568  ...     22.851562 -18.681826  172.442571 -77.518364    0   \n",
       "5628       7.895731  ...     86.132812 -13.708317  218.054844 -20.910333    0   \n",
       "5629      25.025402  ...    133.242188 -24.788561  249.573365  12.560887    0   \n",
       "5630       5.081168  ...     11.074219  -8.084014  117.528357 -70.880802    0   \n",
       "5631       6.621549  ...    340.839844 -32.442867   14.265035 -61.816065    0   \n",
       "5632      22.520668  ...    138.164062 -40.033035  264.026219   5.768998    0   \n",
       "5633       4.973414  ...     28.828125 -25.117701  208.535318 -75.532469    0   \n",
       "5634       4.807910  ...    140.976562   3.732834  228.783975  35.301875    0   \n",
       "5635      13.701665  ...    314.296875 -40.033035    2.071417 -40.445067    0   \n",
       "5636       6.174638  ...     54.316406 -18.524391  209.170030 -51.015495    0   \n",
       "5637       7.174377  ...    304.980469 -14.169522   29.658085 -25.884722    0   \n",
       "5638       4.617105  ...    132.539062  -1.641510  229.063354  25.304821    0   \n",
       "5639       5.092716  ...    164.003906 -31.039240  275.630181  25.642742    0   \n",
       "5640       7.241809  ...    174.902344  -2.089372  269.456940  56.041993    0   \n",
       "5641       4.066229  ...    142.734375 -23.480536  254.430952  19.977762    0   \n",
       "5642       6.013713  ...     90.000000 -20.264481  226.045011 -20.105392    0   \n",
       "5643       6.026685  ...    142.734375 -18.997131  250.892051  23.021357    0   \n",
       "5644      17.767962  ...    294.960938  -4.031936   34.856817 -12.602145    0   \n",
       "5645       5.329577  ...     26.718750 -14.940303  172.342697 -72.255675    0   \n",
       "5646       7.560100  ...    120.101349 -62.696659  275.742955 -16.509746    0   \n",
       "5647      27.798227  ...    203.108109 -55.682144  308.728904   6.727511    0   \n",
       "5648       5.044760  ...     79.101562 -35.501846  239.172243 -33.827844    0   \n",
       "5649      38.742641  ...    301.992188 -17.426323   25.102988 -24.511101    0   \n",
       "\n",
       "      hostgal_specz  hostgal_photoz  hostgal_photoz_err  distmod  mwebv  \n",
       "0            0.0000          0.0000              0.0000   0.0000  0.017  \n",
       "1            0.3037          0.2813              1.1523  40.7951  0.007  \n",
       "2            0.1934          0.2415              0.0176  40.4166  0.024  \n",
       "3            0.1352          0.1820              0.0304  39.7279  0.019  \n",
       "4            0.6857          0.7014              0.0100  43.1524  0.021  \n",
       "5            0.3088          0.3229              0.3360  41.1401  0.027  \n",
       "6            0.0000          0.0000              0.0000   0.0000  0.018  \n",
       "7            0.1516          0.1900              0.0104  39.8317  0.007  \n",
       "8            0.1695          0.5409              0.2283  42.4667  0.020  \n",
       "9            0.0000          0.0000              0.0000   0.0000  0.019  \n",
       "10           0.0000          0.0000              0.0000   0.0000  0.009  \n",
       "11           0.1539          0.1469              0.0094  39.2171  0.020  \n",
       "12           0.1069          0.1274              0.0198  38.8800  0.020  \n",
       "13           0.1610          0.1818              0.0079  39.7258  0.020  \n",
       "14           0.0561          0.0556              0.0301  36.9750  0.010  \n",
       "15           0.0000          0.0000              0.0000   0.0000  0.011  \n",
       "16           0.5149          0.5512              0.0221  42.5158  0.019  \n",
       "17           0.1197          0.1322              0.3351  38.9679  0.009  \n",
       "18           0.2333          0.2205              0.9667  40.1939  0.016  \n",
       "19           0.5919          0.5995              0.0127  42.7370  0.018  \n",
       "20           0.3201          0.2685              0.5211  40.6793  0.018  \n",
       "21           0.0000          0.0000              0.0000   0.0000  0.011  \n",
       "22           0.5680          0.5667              0.0181  42.5888  0.020  \n",
       "23           0.0826          0.0850              0.0073  37.9414  0.007  \n",
       "24           3.4451          0.5176              1.2609  42.3516  0.020  \n",
       "25           0.0000          0.0000              0.0000   0.0000  0.010  \n",
       "26           0.2628          0.1876              0.0216  39.8011  0.018  \n",
       "27           0.0830          0.0820              0.2257  37.8568  0.007  \n",
       "28           0.3779          0.4808              0.2970  42.1592  0.011  \n",
       "29           0.0000          0.0000              0.0000   0.0000  0.018  \n",
       "...             ...             ...                 ...      ...    ...  \n",
       "5620         0.0000          0.0000              0.0000   0.0000  0.126  \n",
       "5621         1.1221          1.8498              0.2668  45.7494  0.056  \n",
       "5622         0.1331          0.1220              0.6970  38.7780  0.616  \n",
       "5623         0.0000          0.0000              0.0000   0.0000  0.015  \n",
       "5624         0.1938          0.4177              0.7828  41.7959  0.041  \n",
       "5625         0.2024          0.5218              0.1283  42.3724  0.052  \n",
       "5626         0.0000          0.0000              0.0000   0.0000  0.013  \n",
       "5627         0.0949          0.1656              0.0257  39.5014  0.014  \n",
       "5628         0.2456          0.3015              0.0576  40.9681  0.187  \n",
       "5629         0.0000          0.0000              0.0000   0.0000  0.131  \n",
       "5630         0.0760          0.0686              0.0194  37.4496  0.028  \n",
       "5631         0.0000          0.0000              0.0000   0.0000  0.010  \n",
       "5632         0.0397          0.0768              0.0149  37.7087  0.417  \n",
       "5633         0.0000          0.0000              0.0000   0.0000  0.011  \n",
       "5634         0.1518          0.1798              0.0301  39.6994  0.032  \n",
       "5635         0.0000          0.0000              0.0000   0.0000  0.036  \n",
       "5636         0.1226          0.1440              0.0172  39.1698  0.061  \n",
       "5637         0.2094          0.2023              0.0118  39.9839  0.061  \n",
       "5638         0.0000          0.0000              0.0000   0.0000  0.015  \n",
       "5639         0.2760          0.2847              0.0109  40.8250  0.070  \n",
       "5640         0.4215          0.3775              0.0206  41.5364  0.024  \n",
       "5641         0.0584          0.0885              0.0149  38.0319  0.056  \n",
       "5642         0.1273          2.6113              0.9733  46.6624  0.043  \n",
       "5643         0.0591          0.0569              0.0248  37.0254  0.045  \n",
       "5644         0.0000          0.0000              0.0000   0.0000  0.291  \n",
       "5645         0.0000          0.0000              0.0000   0.0000  0.013  \n",
       "5646         0.1725          2.5606              1.1146  46.6108  0.136  \n",
       "5647         0.0000          0.0000              0.0000   0.0000  0.430  \n",
       "5648         0.0000          0.0000              0.0000   0.0000  0.034  \n",
       "5649         0.0000          0.0000              0.0000   0.0000  0.091  \n",
       "\n",
       "[5650 rows x 76 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written 12116 rows out of 3492890\n",
      "Written 24245 rows out of 3492890\n",
      "Written 41856 rows out of 3492890\n",
      "Written 73104 rows out of 3492890\n",
      "Written 104341 rows out of 3492890\n",
      "Written 135583 rows out of 3492890\n",
      "Written 166844 rows out of 3492890\n",
      "Written 198095 rows out of 3492890\n",
      "Written 229340 rows out of 3492890\n",
      "Written 260614 rows out of 3492890\n",
      "Written 291872 rows out of 3492890\n",
      "Written 323133 rows out of 3492890\n",
      "Written 354385 rows out of 3492890\n",
      "Written 385651 rows out of 3492890\n",
      "Written 416901 rows out of 3492890\n",
      "Written 448172 rows out of 3492890\n",
      "Written 479459 rows out of 3492890\n",
      "Written 510733 rows out of 3492890\n",
      "Written 541990 rows out of 3492890\n",
      "Written 573236 rows out of 3492890\n",
      "Written 604457 rows out of 3492890\n",
      "Written 635748 rows out of 3492890\n",
      "Written 667007 rows out of 3492890\n",
      "Written 698291 rows out of 3492890\n",
      "Written 729552 rows out of 3492890\n",
      "Written 760786 rows out of 3492890\n",
      "Written 792003 rows out of 3492890\n",
      "Written 823252 rows out of 3492890\n",
      "Written 854519 rows out of 3492890\n",
      "Written 885764 rows out of 3492890\n",
      "Written 917021 rows out of 3492890\n",
      "Written 948312 rows out of 3492890\n",
      "Written 979558 rows out of 3492890\n",
      "Written 1010806 rows out of 3492890\n",
      "Written 1042076 rows out of 3492890\n",
      "Written 1073356 rows out of 3492890\n",
      "Written 1104612 rows out of 3492890\n",
      "Written 1135868 rows out of 3492890\n",
      "Written 1167144 rows out of 3492890\n",
      "Written 1198396 rows out of 3492890\n",
      "Written 1229661 rows out of 3492890\n",
      "Written 1260924 rows out of 3492890\n",
      "Written 1292186 rows out of 3492890\n",
      "Written 1323444 rows out of 3492890\n",
      "Written 1354715 rows out of 3492890\n",
      "Written 1386005 rows out of 3492890\n",
      "Written 1417225 rows out of 3492890\n",
      "Written 1448488 rows out of 3492890\n",
      "Written 1479760 rows out of 3492890\n",
      "Written 1510986 rows out of 3492890\n",
      "Written 1542259 rows out of 3492890\n",
      "Written 1573524 rows out of 3492890\n",
      "Written 1604755 rows out of 3492890\n",
      "Written 1635966 rows out of 3492890\n",
      "Written 1667154 rows out of 3492890\n",
      "Written 1698385 rows out of 3492890\n",
      "Written 1729584 rows out of 3492890\n",
      "Written 1760836 rows out of 3492890\n",
      "Written 1792079 rows out of 3492890\n",
      "Written 1823348 rows out of 3492890\n",
      "Written 1854617 rows out of 3492890\n",
      "Written 1885889 rows out of 3492890\n",
      "Written 1917175 rows out of 3492890\n",
      "Written 1948402 rows out of 3492890\n",
      "Written 1979672 rows out of 3492890\n",
      "Written 2010936 rows out of 3492890\n",
      "Written 2042148 rows out of 3492890\n",
      "Written 2073411 rows out of 3492890\n",
      "Written 2104654 rows out of 3492890\n",
      "Written 2135925 rows out of 3492890\n",
      "Written 2167196 rows out of 3492890\n",
      "Written 2198456 rows out of 3492890\n",
      "Written 2229720 rows out of 3492890\n",
      "Written 2260981 rows out of 3492890\n",
      "Written 2292222 rows out of 3492890\n",
      "Written 2323487 rows out of 3492890\n",
      "Written 2354743 rows out of 3492890\n",
      "Written 2386015 rows out of 3492890\n",
      "Written 2417255 rows out of 3492890\n",
      "Written 2448503 rows out of 3492890\n",
      "Written 2479791 rows out of 3492890\n",
      "Written 2511074 rows out of 3492890\n",
      "Written 2542325 rows out of 3492890\n",
      "Written 2573614 rows out of 3492890\n",
      "Written 2604925 rows out of 3492890\n",
      "Written 2636179 rows out of 3492890\n",
      "Written 2667421 rows out of 3492890\n",
      "Written 2698666 rows out of 3492890\n",
      "Written 2729918 rows out of 3492890\n",
      "Written 2761151 rows out of 3492890\n",
      "Written 2792412 rows out of 3492890\n",
      "Written 2823661 rows out of 3492890\n",
      "Written 2854919 rows out of 3492890\n",
      "Written 2886156 rows out of 3492890\n",
      "Written 2917389 rows out of 3492890\n",
      "Written 2948654 rows out of 3492890\n",
      "Written 2979904 rows out of 3492890\n",
      "Written 3011157 rows out of 3492890\n",
      "Written 3042426 rows out of 3492890\n",
      "Written 3073660 rows out of 3492890\n",
      "Written 3104915 rows out of 3492890\n",
      "Written 3136203 rows out of 3492890\n",
      "Written 3167436 rows out of 3492890\n",
      "Written 3198717 rows out of 3492890\n",
      "Written 3229983 rows out of 3492890\n",
      "Written 3261246 rows out of 3492890\n",
      "Written 3292488 rows out of 3492890\n",
      "Written 3323739 rows out of 3492890\n",
      "Written 3355016 rows out of 3492890\n",
      "Written 3386240 rows out of 3492890\n",
      "Written 3417486 rows out of 3492890\n",
      "Written 3448738 rows out of 3492890\n",
      "Written 3479982 rows out of 3492890\n",
      "Written 3492889 rows out of 3492890\n",
      "Done. The final row count is 3492890\n",
      "That took 13.63 minutes\n"
     ]
    }
   ],
   "source": [
    "gc.enable()\n",
    "generate_kaggle_submission(model = best_rf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                13\n",
       "1                14\n",
       "2                17\n",
       "3                23\n",
       "4                34\n",
       "5                35\n",
       "6                43\n",
       "7                50\n",
       "8                60\n",
       "9                69\n",
       "10               88\n",
       "11               96\n",
       "12              106\n",
       "13              114\n",
       "14              115\n",
       "15              116\n",
       "16              130\n",
       "17              142\n",
       "18              147\n",
       "19              151\n",
       "20              168\n",
       "21              171\n",
       "22              173\n",
       "23              176\n",
       "24              184\n",
       "25              186\n",
       "26              195\n",
       "27              198\n",
       "28              204\n",
       "29              211\n",
       "            ...    \n",
       "729522    130787078\n",
       "729523    130787121\n",
       "729524    130787259\n",
       "729525    130787288\n",
       "729526    130787315\n",
       "729527    130787346\n",
       "729528    130787409\n",
       "729529    130787413\n",
       "729530    130787553\n",
       "729531    130787572\n",
       "729532    130787650\n",
       "729533    130787683\n",
       "729534    130787746\n",
       "729535    130787754\n",
       "729536    130787792\n",
       "729537    130787808\n",
       "729538    130787817\n",
       "729539    130787819\n",
       "729540    130787871\n",
       "729541    130787879\n",
       "729542    130787887\n",
       "729543    130787903\n",
       "729544    130787932\n",
       "729545    130787944\n",
       "729546    130787965\n",
       "729547    130787966\n",
       "729548    130787971\n",
       "729549    130787974\n",
       "729550    130788053\n",
       "729551    130788054\n",
       "Name: object_id, Length: 3492888, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0                 13\n",
       "1                 14\n",
       "2                 17\n",
       "3                 23\n",
       "4                 34\n",
       "5                 35\n",
       "6                 43\n",
       "7                 50\n",
       "8                 60\n",
       "9                 69\n",
       "10                88\n",
       "11                96\n",
       "12               106\n",
       "13               114\n",
       "14               115\n",
       "15               116\n",
       "16               130\n",
       "17               142\n",
       "18               147\n",
       "19               151\n",
       "20               168\n",
       "21               171\n",
       "22               173\n",
       "23               176\n",
       "24               184\n",
       "25               186\n",
       "26               195\n",
       "27               198\n",
       "28               204\n",
       "29               211\n",
       "             ...    \n",
       "3492860    130787078\n",
       "3492861    130787121\n",
       "3492862    130787259\n",
       "3492863    130787288\n",
       "3492864    130787315\n",
       "3492865    130787346\n",
       "3492866    130787409\n",
       "3492867    130787413\n",
       "3492868    130787553\n",
       "3492869    130787572\n",
       "3492870    130787650\n",
       "3492871    130787683\n",
       "3492872    130787746\n",
       "3492873    130787754\n",
       "3492874    130787792\n",
       "3492875    130787808\n",
       "3492876    130787817\n",
       "3492877    130787819\n",
       "3492878    130787871\n",
       "3492879    130787879\n",
       "3492880    130787887\n",
       "3492881    130787903\n",
       "3492882    130787932\n",
       "3492883    130787944\n",
       "3492884    130787965\n",
       "3492885    130787966\n",
       "3492886    130787971\n",
       "3492887    130787974\n",
       "3492888    130788053\n",
       "3492889    130788054\n",
       "Name: object_id, Length: 3492890, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-157-48c4f5e783c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msub_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0msub_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mmeta_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'not equal at index'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1477\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1478\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1480\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   2083\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2084\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2085\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2086\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2087\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getbool_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/common.py\u001b[0m in \u001b[0;36mis_bool_indexer\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mis_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mABCSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "check_sub = pd.read_csv('../submissions/submission.csv')\n",
    "tsm = pd.read_csv('../data/test_set_metadata.csv')\n",
    "\n",
    "tsm.sort_values(by = 'object_id', inplace = True)\n",
    "\n",
    "\n",
    "sub_obj = check_sub['object_id'].copy()\n",
    "meta_obj = tsm['object_id'].copy()\n",
    "\n",
    "sub_obj.sort_values(inplace = True)\n",
    "meta_obj.sort_values(inplace = True)\n",
    "\n",
    "display(sub_obj)\n",
    "display(meta_obj)\n",
    "for i in sub_obj.index:\n",
    "    if sub_obj.iloc[i] != meta_obj.iloc[i]:\n",
    "        print('not equal at index', i)\n",
    "        print(sub_obj.loc[i], meta_obj.loc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running cv for min_number_samples = 2\n",
      "running cv for min_number_samples = 3\n",
      "running cv for min_number_samples = 4\n",
      "running cv for min_number_samples = 5\n",
      "running cv for min_number_samples = 6\n",
      "running cv for min_number_samples = 7\n",
      "running cv for min_number_samples = 8\n",
      "running cv for min_number_samples = 9\n",
      "running cv for min_number_samples = 10\n",
      "running cv for min_number_samples = 11\n",
      "running cv for min_number_samples = 12\n",
      "running cv for min_number_samples = 13\n",
      "running cv for min_number_samples = 14\n",
      "running cv for min_number_samples = 15\n",
      "running cv for min_number_samples = 16\n",
      "running cv for min_number_samples = 17\n",
      "running cv for min_number_samples = 18\n",
      "running cv for min_number_samples = 19\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.2511472833462389,\n",
       " 0.2507875588638411,\n",
       " 0.24759854479078613,\n",
       " 0.24973027277711435,\n",
       " 0.2513285202584179,\n",
       " 0.25026233727129754,\n",
       " 0.2522101957725178,\n",
       " 0.25344122618242837,\n",
       " 0.2546828072364937,\n",
       " 0.2534349575215634,\n",
       " 0.25591442343667214,\n",
       " 0.2557363357414042,\n",
       " 0.2562710667738106,\n",
       " 0.25752029913805563,\n",
       " 0.25503053277375864,\n",
       " 0.25909640519250565,\n",
       " 0.25663017628786433,\n",
       " 0.25662129427839253]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "params = range(2, 20, 1)\n",
    "cv_curve2(params, training_features, training_labels, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running cv for p = 40\n",
      "running cv for p = 50\n",
      "running cv for p = 60\n",
      "running cv for p = 70\n",
      "running cv for p = 80\n",
      "running cv for p = 90\n",
      "running cv for p = 100\n",
      "running cv for p = 110\n",
      "running cv for p = 120\n",
      "running cv for p = 130\n",
      "running cv for p = 140\n",
      "running cv for p = 150\n",
      "running cv for p = 160\n",
      "running cv for p = 170\n",
      "running cv for p = 180\n",
      "running cv for p = 190\n",
      "running cv for p = 200\n",
      "running cv for p = 210\n",
      "running cv for p = 220\n",
      "running cv for p = 230\n",
      "running cv for p = 240\n",
      "running cv for p = 250\n",
      "running cv for p = 260\n",
      "running cv for p = 270\n",
      "running cv for p = 280\n",
      "running cv for p = 290\n",
      "running cv for p = 300\n",
      "running cv for p = 310\n",
      "running cv for p = 320\n",
      "running cv for p = 330\n",
      "running cv for p = 340\n",
      "running cv for p = 350\n",
      "running cv for p = 360\n",
      "running cv for p = 370\n",
      "running cv for p = 380\n",
      "running cv for p = 390\n",
      "running cv for p = 400\n",
      "running cv for p = 410\n",
      "running cv for p = 420\n",
      "running cv for p = 430\n",
      "running cv for p = 440\n",
      "running cv for p = 450\n",
      "running cv for p = 460\n",
      "running cv for p = 470\n",
      "running cv for p = 480\n",
      "running cv for p = 490\n",
      "running cv for p = 500\n",
      "running cv for p = 510\n",
      "running cv for p = 520\n",
      "running cv for p = 530\n",
      "running cv for p = 540\n",
      "running cv for p = 550\n",
      "running cv for p = 560\n",
      "running cv for p = 570\n",
      "running cv for p = 580\n",
      "running cv for p = 590\n",
      "running cv for p = 600\n",
      "running cv for p = 610\n",
      "running cv for p = 620\n",
      "running cv for p = 630\n",
      "running cv for p = 640\n",
      "running cv for p = 650\n",
      "running cv for p = 660\n",
      "running cv for p = 670\n",
      "running cv for p = 680\n",
      "running cv for p = 690\n",
      "running cv for p = 700\n",
      "running cv for p = 710\n",
      "running cv for p = 720\n",
      "running cv for p = 730\n",
      "running cv for p = 740\n",
      "running cv for p = 750\n",
      "running cv for p = 760\n",
      "running cv for p = 770\n",
      "running cv for p = 780\n",
      "running cv for p = 790\n",
      "running cv for p = 800\n",
      "running cv for p = 810\n",
      "running cv for p = 820\n",
      "running cv for p = 830\n",
      "running cv for p = 840\n",
      "running cv for p = 850\n",
      "running cv for p = 860\n",
      "running cv for p = 870\n",
      "running cv for p = 880\n",
      "running cv for p = 890\n",
      "running cv for p = 900\n",
      "running cv for p = 910\n",
      "running cv for p = 920\n",
      "running cv for p = 930\n",
      "running cv for p = 940\n",
      "running cv for p = 950\n",
      "running cv for p = 960\n",
      "running cv for p = 970\n",
      "running cv for p = 980\n",
      "running cv for p = 990\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0.2559590320818762,\n",
       " 0.2591066940127822,\n",
       " 0.25753261969123487,\n",
       " 0.2513174528114446,\n",
       " 0.2557642489338121,\n",
       " 0.2529364159932609,\n",
       " 0.2546812324339359,\n",
       " 0.25414788344707695,\n",
       " 0.25097876732165036,\n",
       " 0.24743589784636866,\n",
       " 0.2539902702191371,\n",
       " 0.25079555831078726,\n",
       " 0.249917427863935,\n",
       " 0.2509824858421681,\n",
       " 0.25289772788104203,\n",
       " 0.25361804003084687,\n",
       " 0.25258089113210247,\n",
       " 0.2490318170518797,\n",
       " 0.25150470765953037,\n",
       " 0.2493925061557094,\n",
       " 0.25044468187256697,\n",
       " 0.25080252429315986,\n",
       " 0.2499250667120677,\n",
       " 0.2516867424316148,\n",
       " 0.2490138651425623,\n",
       " 0.2493762635997575,\n",
       " 0.24921535489576896,\n",
       " 0.2514947113575292,\n",
       " 0.25168547267102426,\n",
       " 0.24937485602634868,\n",
       " 0.2504460737924499,\n",
       " 0.24813920128445877,\n",
       " 0.24990944072019916,\n",
       " 0.25043932646862477,\n",
       " 0.24778821179867772,\n",
       " 0.2490251378085928,\n",
       " 0.2486601851159047,\n",
       " 0.2476117909835167,\n",
       " 0.2521984852505148,\n",
       " 0.2475953723160521,\n",
       " 0.24742167282447014,\n",
       " 0.2485017899903712,\n",
       " 0.24867657969241086,\n",
       " 0.24742713625938695,\n",
       " 0.2490291770423767,\n",
       " 0.24795298444918623,\n",
       " 0.2520418342856633,\n",
       " 0.24883718594214344,\n",
       " 0.25043528633117373,\n",
       " 0.24903074842408768,\n",
       " 0.24902604195378375,\n",
       " 0.2506213262834429,\n",
       " 0.24849756962848835,\n",
       " 0.24990242178646516,\n",
       " 0.2477746058402689,\n",
       " 0.25025529827121906,\n",
       " 0.24795282079083358,\n",
       " 0.2474285663280148,\n",
       " 0.25062149085434915,\n",
       " 0.25044356096771225,\n",
       " 0.25043888192090835,\n",
       " 0.2476035662656979,\n",
       " 0.24973605365440044,\n",
       " 0.24743322713358162,\n",
       " 0.24601719379788545,\n",
       " 0.2479690840874289,\n",
       " 0.24654630008647893,\n",
       " 0.2518546750948102,\n",
       " 0.25044201123919807,\n",
       " 0.24707287865052618,\n",
       " 0.24884282306858496,\n",
       " 0.24813233353814335,\n",
       " 0.24866940036233443,\n",
       " 0.24938067094834737,\n",
       " 0.24725016203239958,\n",
       " 0.24973151920046355,\n",
       " 0.2484902107571657,\n",
       " 0.2493753669883324,\n",
       " 0.2477761738805514,\n",
       " 0.24689917003832573,\n",
       " 0.24919868276244073,\n",
       " 0.2469032308458884,\n",
       " 0.24954986835554727,\n",
       " 0.24989727068902645,\n",
       " 0.24796207669430126,\n",
       " 0.24848866353694476,\n",
       " 0.25114997973683706,\n",
       " 0.24920165169327502,\n",
       " 0.24866817133819996,\n",
       " 0.2502614281889386,\n",
       " 0.2490211958277807,\n",
       " 0.24884875772988801,\n",
       " 0.2486680142921729,\n",
       " 0.24955283234032688,\n",
       " 0.2481398486223576,\n",
       " 0.24813951788480582]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "params = range(40, 1000, 10)\n",
    "cv_curve(params, training_features, training_labels, test_features, test_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_avg_nest = [0.2559590320818762,\n",
    " 0.2591066940127822,\n",
    " 0.25753261969123487,\n",
    " 0.2513174528114446,\n",
    " 0.2557642489338121,\n",
    " 0.2529364159932609,\n",
    " 0.2546812324339359,\n",
    " 0.25414788344707695,\n",
    " 0.25097876732165036,\n",
    " 0.24743589784636866,\n",
    " 0.2539902702191371,\n",
    " 0.25079555831078726,\n",
    " 0.249917427863935,\n",
    " 0.2509824858421681,\n",
    " 0.25289772788104203,\n",
    " 0.25361804003084687,\n",
    " 0.25258089113210247,\n",
    " 0.2490318170518797,\n",
    " 0.25150470765953037,\n",
    " 0.2493925061557094,\n",
    " 0.25044468187256697,\n",
    " 0.25080252429315986,\n",
    " 0.2499250667120677,\n",
    " 0.2516867424316148,\n",
    " 0.2490138651425623,\n",
    " 0.2493762635997575,\n",
    " 0.24921535489576896,\n",
    " 0.2514947113575292,\n",
    " 0.25168547267102426,\n",
    " 0.24937485602634868,\n",
    " 0.2504460737924499,\n",
    " 0.24813920128445877,\n",
    " 0.24990944072019916,\n",
    " 0.25043932646862477,\n",
    " 0.24778821179867772,\n",
    " 0.2490251378085928,\n",
    " 0.2486601851159047,\n",
    " 0.2476117909835167,\n",
    " 0.2521984852505148,\n",
    " 0.2475953723160521,\n",
    " 0.24742167282447014,\n",
    " 0.2485017899903712,\n",
    " 0.24867657969241086,\n",
    " 0.24742713625938695,\n",
    " 0.2490291770423767,\n",
    " 0.24795298444918623,\n",
    " 0.2520418342856633,\n",
    " 0.24883718594214344,\n",
    " 0.25043528633117373,\n",
    " 0.24903074842408768,\n",
    " 0.24902604195378375,\n",
    " 0.2506213262834429,\n",
    " 0.24849756962848835,\n",
    " 0.24990242178646516,\n",
    " 0.2477746058402689,\n",
    " 0.25025529827121906,\n",
    " 0.24795282079083358,\n",
    " 0.2474285663280148,\n",
    " 0.25062149085434915,\n",
    " 0.25044356096771225,\n",
    " 0.25043888192090835,\n",
    " 0.2476035662656979,\n",
    " 0.24973605365440044,\n",
    " 0.24743322713358162,\n",
    " 0.24601719379788545,\n",
    " 0.2479690840874289,\n",
    " 0.24654630008647893,\n",
    " 0.2518546750948102,\n",
    " 0.25044201123919807,\n",
    " 0.24707287865052618,\n",
    " 0.24884282306858496,\n",
    " 0.24813233353814335,\n",
    " 0.24866940036233443,\n",
    " 0.24938067094834737,\n",
    " 0.24725016203239958,\n",
    " 0.24973151920046355,\n",
    " 0.2484902107571657,\n",
    " 0.2493753669883324,\n",
    " 0.2477761738805514,\n",
    " 0.24689917003832573,\n",
    " 0.24919868276244073,\n",
    " 0.2469032308458884,\n",
    " 0.24954986835554727,\n",
    " 0.24989727068902645,\n",
    " 0.24796207669430126,\n",
    " 0.24848866353694476,\n",
    " 0.25114997973683706,\n",
    " 0.24920165169327502,\n",
    " 0.24866817133819996,\n",
    " 0.2502614281889386,\n",
    " 0.2490211958277807,\n",
    " 0.24884875772988801,\n",
    " 0.2486680142921729,\n",
    " 0.24955283234032688,\n",
    " 0.2481398486223576,\n",
    " 0.24813951788480582]\n",
    "\n",
    "cv_avg_split = [0.2511472833462389,\n",
    " 0.2507875588638411,\n",
    " 0.24759854479078613,\n",
    " 0.24973027277711435,\n",
    " 0.2513285202584179,\n",
    " 0.25026233727129754,\n",
    " 0.2522101957725178,\n",
    " 0.25344122618242837,\n",
    " 0.2546828072364937,\n",
    " 0.2534349575215634,\n",
    " 0.25591442343667214,\n",
    " 0.2557363357414042,\n",
    " 0.2562710667738106,\n",
    " 0.25752029913805563,\n",
    " 0.25503053277375864,\n",
    " 0.25909640519250565,\n",
    " 0.25663017628786433,\n",
    " 0.25662129427839253]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "|****                Random    Forest                      ****|\n",
      "cv scores:  0.77836 0.79487 0.78034 0.77039 0.78311\n",
      "cv average: 0.7814147348090102\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ig_training_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-8c54e5de2f59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#dt, dt_avg_cv = decision_tree_cv(training_features, training_labels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mrf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrf_avg_cv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_forest_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mrf2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrf_avg_cv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_forest_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mig_training_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mig_training_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mrf3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrf_avg_cv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_forest_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meg_training_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meg_training_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ig_training_features' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "#gnb, gnb_avg_cv = gaussian_naive_bayes_cv(training_features, training_labels)\n",
    "#log, log_avg_cv = logistic_regression_cv(training_features, training_labels)\n",
    "#dt, dt_avg_cv = decision_tree_cv(training_features, training_labels)\n",
    "rf, rf_avg_cv = random_forest_cv(training_features, training_labels, nest = 300, min_split = 4)\n",
    "rf2, rf_avg_cv = random_forest_cv(ig_training_features, ig_training_labels, nest = 300, min_split = 4)\n",
    "rf3, rf_avg_cv = random_forest_cv(eg_training_features, eg_training_labels, nest = 300, min_split = 4)\n",
    "\n",
    "\n",
    "# lgb, lgb_avg_cv = lgbm_cv(training_features, training_labels)\n",
    "\n",
    "#gnb, gnb_avg_cv = gaussian_naive_bayes_cv(nm_training_features, training_labels)\n",
    "#log, log_avg_cv = logistic_regression_cv(training_features, training_labels)\n",
    "#dt, dt_avg_cv = decision_tree_cv(nm_training_features, training_labels)\n",
    "#rf, rf_avg_cv = random_forest_cv(nm_training_features, training_labels)\n",
    "#ab, ab_avg_cv = adaboost_cv(nm_training_features, training_labels)\n",
    "#lgb = lgbm_cv(nm_training_features, training_labels)\n",
    "\n",
    "#y_pred = lgb.predict(test_features)\n",
    "\n",
    "#from sklearn.metrics import accuracy_score\n",
    "\n",
    "#accuracy_score(y_pred, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
